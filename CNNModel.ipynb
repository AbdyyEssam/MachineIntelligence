{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d35376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ad6c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path('/Users/geek/Downloads/geek/heart/0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c5cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "labels = list(map(lambda x: '0', filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "zerosimage_df = pd.concat([filepaths, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33e8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir2 = Path('/Users/geek/Downloads/geek/heart/1')\n",
    "filepaths2 = list(image_dir2.glob(r'**/*.png'))\n",
    "labels2 = list(map(lambda x: '1', filepaths2))\n",
    "\n",
    "filepaths2 = pd.Series(filepaths2, name='Filepath').astype(str)\n",
    "labels2 = pd.Series(labels2, name='Label')\n",
    "\n",
    "onesimage_df = pd.concat([filepaths2, labels2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f2f698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/613_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1210_8.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/512_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/818_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1120_5.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/912_1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1212_7.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1210_5.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1312_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/315_4.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filepath Label\n",
       "0     /Users/geek/Downloads/geek/heart/0/613_2.png     0\n",
       "1    /Users/geek/Downloads/geek/heart/0/1210_8.png     0\n",
       "2     /Users/geek/Downloads/geek/heart/0/512_2.png     0\n",
       "3     /Users/geek/Downloads/geek/heart/0/818_2.png     0\n",
       "4    /Users/geek/Downloads/geek/heart/0/1120_5.png     0\n",
       "..                                             ...   ...\n",
       "387   /Users/geek/Downloads/geek/heart/0/912_1.png     0\n",
       "388  /Users/geek/Downloads/geek/heart/0/1212_7.png     0\n",
       "389  /Users/geek/Downloads/geek/heart/0/1210_5.png     0\n",
       "390  /Users/geek/Downloads/geek/heart/0/1312_2.png     0\n",
       "391   /Users/geek/Downloads/geek/heart/0/315_4.png     0\n",
       "\n",
       "[392 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zerosimage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d6989b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/118_1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/613_2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/2812_6.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/1210_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/29_2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/378_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/910_3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/1210_5.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/711_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/2410_7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>953 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filepath Label\n",
       "0     /Users/geek/Downloads/geek/heart/1/118_1.png     1\n",
       "1     /Users/geek/Downloads/geek/heart/1/613_2.png     1\n",
       "2    /Users/geek/Downloads/geek/heart/1/2812_6.png     1\n",
       "3    /Users/geek/Downloads/geek/heart/1/1210_8.png     1\n",
       "4      /Users/geek/Downloads/geek/heart/1/29_2.png     1\n",
       "..                                             ...   ...\n",
       "948   /Users/geek/Downloads/geek/heart/1/378_8.png     1\n",
       "949   /Users/geek/Downloads/geek/heart/1/910_3.png     1\n",
       "950  /Users/geek/Downloads/geek/heart/1/1210_5.png     1\n",
       "951   /Users/geek/Downloads/geek/heart/1/711_8.png     1\n",
       "952  /Users/geek/Downloads/geek/heart/1/2410_7.png     1\n",
       "\n",
       "[953 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onesimage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6100c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df1 = [zerosimage_df,onesimage_df]\n",
    "image_df = pd.concat(image_df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d886fb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/613_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1210_8.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/512_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/818_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1120_5.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/378_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/910_3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/1210_5.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/711_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/2410_7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1345 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filepath Label\n",
       "0     /Users/geek/Downloads/geek/heart/0/613_2.png     0\n",
       "1    /Users/geek/Downloads/geek/heart/0/1210_8.png     0\n",
       "2     /Users/geek/Downloads/geek/heart/0/512_2.png     0\n",
       "3     /Users/geek/Downloads/geek/heart/0/818_2.png     0\n",
       "4    /Users/geek/Downloads/geek/heart/0/1120_5.png     0\n",
       "..                                             ...   ...\n",
       "948   /Users/geek/Downloads/geek/heart/1/378_8.png     1\n",
       "949   /Users/geek/Downloads/geek/heart/1/910_3.png     1\n",
       "950  /Users/geek/Downloads/geek/heart/1/1210_5.png     1\n",
       "951   /Users/geek/Downloads/geek/heart/1/711_8.png     1\n",
       "952  /Users/geek/Downloads/geek/heart/1/2410_7.png     1\n",
       "\n",
       "[1345 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa64d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = train_test_split(image_df,train_size=0.7, shuffle = True , random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8205689a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/3517_6.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1015_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/329_2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1121_1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/614_7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/3210_7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/1110_2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/811_5.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1211_4.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/310_2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>941 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filepath Label\n",
       "666  /Users/geek/Downloads/geek/heart/1/3517_6.png     1\n",
       "323  /Users/geek/Downloads/geek/heart/0/1015_2.png     0\n",
       "543   /Users/geek/Downloads/geek/heart/1/329_2.png     1\n",
       "134  /Users/geek/Downloads/geek/heart/0/1121_1.png     0\n",
       "262   /Users/geek/Downloads/geek/heart/1/614_7.png     1\n",
       "..                                             ...   ...\n",
       "323  /Users/geek/Downloads/geek/heart/1/3210_7.png     1\n",
       "513  /Users/geek/Downloads/geek/heart/1/1110_2.png     1\n",
       "704   /Users/geek/Downloads/geek/heart/1/811_5.png     1\n",
       "235  /Users/geek/Downloads/geek/heart/0/1211_4.png     0\n",
       "669   /Users/geek/Downloads/geek/heart/1/310_2.png     1\n",
       "\n",
       "[941 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bb56980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/1211_2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1311_3.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1121_5.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/1813_1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1314_3.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/1311_1.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/0/1015_6.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/158_6.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/1713_4.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>/Users/geek/Downloads/geek/heart/1/1510_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Filepath Label\n",
       "510  /Users/geek/Downloads/geek/heart/1/1211_2.png     1\n",
       "267  /Users/geek/Downloads/geek/heart/0/1311_3.png     0\n",
       "111  /Users/geek/Downloads/geek/heart/0/1121_5.png     0\n",
       "746  /Users/geek/Downloads/geek/heart/1/1813_1.png     1\n",
       "315  /Users/geek/Downloads/geek/heart/0/1314_3.png     0\n",
       "..                                             ...   ...\n",
       "614  /Users/geek/Downloads/geek/heart/1/1311_1.png     1\n",
       "347  /Users/geek/Downloads/geek/heart/0/1015_6.png     0\n",
       "268   /Users/geek/Downloads/geek/heart/1/158_6.png     1\n",
       "269  /Users/geek/Downloads/geek/heart/1/1713_4.png     1\n",
       "591  /Users/geek/Downloads/geek/heart/1/1510_8.png     1\n",
       "\n",
       "[404 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bebd20bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344d1067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 753 validated image filenames belonging to 2 classes.\n",
      "Found 188 validated image filenames belonging to 2 classes.\n",
      "Found 404 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68e05a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 14:09:21.126314: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-28 14:09:21.126503: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 14:09:21.487562: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-12-28 14:09:21.642537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - ETA: 0s - loss: 0.6433 - accuracy: 0.7198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 14:09:26.812938: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 6s 255ms/step - loss: 0.6433 - accuracy: 0.7198 - val_loss: 0.6492 - val_accuracy: 0.6915\n",
      "Epoch 2/120\n",
      "24/24 [==============================] - 6s 246ms/step - loss: 0.6242 - accuracy: 0.7198 - val_loss: 0.6300 - val_accuracy: 0.6915\n",
      "Epoch 3/120\n",
      "24/24 [==============================] - 6s 236ms/step - loss: 0.6018 - accuracy: 0.7198 - val_loss: 0.6125 - val_accuracy: 0.6915\n",
      "Epoch 4/120\n",
      "24/24 [==============================] - 6s 230ms/step - loss: 0.5831 - accuracy: 0.7198 - val_loss: 0.6032 - val_accuracy: 0.6915\n",
      "Epoch 5/120\n",
      "24/24 [==============================] - 6s 230ms/step - loss: 0.5667 - accuracy: 0.7198 - val_loss: 0.5829 - val_accuracy: 0.6915\n",
      "Epoch 6/120\n",
      "24/24 [==============================] - 6s 238ms/step - loss: 0.5408 - accuracy: 0.7198 - val_loss: 0.5521 - val_accuracy: 0.6968\n",
      "Epoch 7/120\n",
      "24/24 [==============================] - 6s 244ms/step - loss: 0.4811 - accuracy: 0.7477 - val_loss: 0.4812 - val_accuracy: 0.7500\n",
      "Epoch 8/120\n",
      "24/24 [==============================] - 6s 240ms/step - loss: 0.4343 - accuracy: 0.7928 - val_loss: 0.4941 - val_accuracy: 0.7340\n",
      "Epoch 9/120\n",
      "24/24 [==============================] - 6s 231ms/step - loss: 0.4465 - accuracy: 0.7968 - val_loss: 0.4789 - val_accuracy: 0.7713\n",
      "Epoch 10/120\n",
      "24/24 [==============================] - 6s 240ms/step - loss: 0.4473 - accuracy: 0.7769 - val_loss: 0.4323 - val_accuracy: 0.7819\n",
      "Epoch 11/120\n",
      "24/24 [==============================] - 6s 245ms/step - loss: 0.4411 - accuracy: 0.7689 - val_loss: 0.4582 - val_accuracy: 0.7766\n",
      "Epoch 12/120\n",
      "24/24 [==============================] - 6s 242ms/step - loss: 0.4422 - accuracy: 0.7955 - val_loss: 0.4484 - val_accuracy: 0.7660\n",
      "Epoch 13/120\n",
      "24/24 [==============================] - 5s 228ms/step - loss: 0.4547 - accuracy: 0.7703 - val_loss: 0.4765 - val_accuracy: 0.7500\n",
      "Epoch 14/120\n",
      "24/24 [==============================] - 5s 227ms/step - loss: 0.4520 - accuracy: 0.7769 - val_loss: 0.4963 - val_accuracy: 0.7340\n",
      "Epoch 15/120\n",
      "24/24 [==============================] - 6s 244ms/step - loss: 0.4201 - accuracy: 0.7875 - val_loss: 0.4793 - val_accuracy: 0.7660\n",
      "Epoch 16/120\n",
      "24/24 [==============================] - 6s 250ms/step - loss: 0.4321 - accuracy: 0.7875 - val_loss: 0.4631 - val_accuracy: 0.7340\n",
      "Epoch 17/120\n",
      "24/24 [==============================] - 6s 230ms/step - loss: 0.4354 - accuracy: 0.7849 - val_loss: 0.4305 - val_accuracy: 0.7713\n",
      "Epoch 18/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.4390 - accuracy: 0.7995 - val_loss: 0.4838 - val_accuracy: 0.7713\n",
      "Epoch 19/120\n",
      "24/24 [==============================] - 5s 226ms/step - loss: 0.4377 - accuracy: 0.7862 - val_loss: 0.4581 - val_accuracy: 0.7606\n",
      "Epoch 20/120\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.4130 - accuracy: 0.8127 - val_loss: 0.4502 - val_accuracy: 0.8032\n",
      "Epoch 21/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.4385 - accuracy: 0.7782 - val_loss: 0.3977 - val_accuracy: 0.7979\n",
      "Epoch 22/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3937 - accuracy: 0.8088 - val_loss: 0.4091 - val_accuracy: 0.7926\n",
      "Epoch 23/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.4319 - accuracy: 0.7835 - val_loss: 0.5296 - val_accuracy: 0.7447\n",
      "Epoch 24/120\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.4365 - accuracy: 0.7756 - val_loss: 0.4389 - val_accuracy: 0.8191\n",
      "Epoch 25/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.4402 - accuracy: 0.7835 - val_loss: 0.5008 - val_accuracy: 0.7606\n",
      "Epoch 26/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.4290 - accuracy: 0.7809 - val_loss: 0.4130 - val_accuracy: 0.7819\n",
      "Epoch 27/120\n",
      "24/24 [==============================] - 6s 230ms/step - loss: 0.4112 - accuracy: 0.7862 - val_loss: 0.4590 - val_accuracy: 0.7394\n",
      "Epoch 28/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3926 - accuracy: 0.7942 - val_loss: 0.3892 - val_accuracy: 0.8032\n",
      "Epoch 29/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.4099 - accuracy: 0.7835 - val_loss: 0.4351 - val_accuracy: 0.7819\n",
      "Epoch 30/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.4066 - accuracy: 0.8101 - val_loss: 0.4223 - val_accuracy: 0.7713\n",
      "Epoch 31/120\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.4097 - accuracy: 0.7981 - val_loss: 0.4047 - val_accuracy: 0.8404\n",
      "Epoch 32/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3980 - accuracy: 0.7902 - val_loss: 0.4075 - val_accuracy: 0.8085\n",
      "Epoch 33/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.4176 - accuracy: 0.7862 - val_loss: 0.4301 - val_accuracy: 0.8032\n",
      "Epoch 34/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3991 - accuracy: 0.7875 - val_loss: 0.4493 - val_accuracy: 0.7766\n",
      "Epoch 35/120\n",
      "24/24 [==============================] - 5s 226ms/step - loss: 0.4081 - accuracy: 0.7968 - val_loss: 0.4041 - val_accuracy: 0.7979\n",
      "Epoch 36/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.4192 - accuracy: 0.7902 - val_loss: 0.4649 - val_accuracy: 0.7819\n",
      "Epoch 37/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.4107 - accuracy: 0.8008 - val_loss: 0.4332 - val_accuracy: 0.7660\n",
      "Epoch 38/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.4209 - accuracy: 0.7849 - val_loss: 0.4228 - val_accuracy: 0.7660\n",
      "Epoch 39/120\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.3972 - accuracy: 0.8114 - val_loss: 0.4250 - val_accuracy: 0.7447\n",
      "Epoch 40/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3908 - accuracy: 0.8101 - val_loss: 0.4329 - val_accuracy: 0.7926\n",
      "Epoch 41/120\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.4120 - accuracy: 0.7928 - val_loss: 0.4724 - val_accuracy: 0.7766\n",
      "Epoch 42/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3888 - accuracy: 0.7968 - val_loss: 0.4414 - val_accuracy: 0.7606\n",
      "Epoch 43/120\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.3865 - accuracy: 0.7968 - val_loss: 0.3894 - val_accuracy: 0.8245\n",
      "Epoch 44/120\n",
      "24/24 [==============================] - 5s 226ms/step - loss: 0.3976 - accuracy: 0.8035 - val_loss: 0.3674 - val_accuracy: 0.8191\n",
      "Epoch 45/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.4005 - accuracy: 0.7995 - val_loss: 0.4525 - val_accuracy: 0.7234\n",
      "Epoch 46/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3952 - accuracy: 0.7955 - val_loss: 0.4052 - val_accuracy: 0.7926\n",
      "Epoch 47/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3920 - accuracy: 0.8021 - val_loss: 0.3834 - val_accuracy: 0.8245\n",
      "Epoch 48/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3860 - accuracy: 0.7968 - val_loss: 0.4044 - val_accuracy: 0.8191\n",
      "Epoch 49/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3900 - accuracy: 0.7968 - val_loss: 0.3955 - val_accuracy: 0.8191\n",
      "Epoch 50/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3727 - accuracy: 0.8220 - val_loss: 0.3970 - val_accuracy: 0.8245\n",
      "Epoch 51/120\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.3708 - accuracy: 0.8074 - val_loss: 0.3794 - val_accuracy: 0.7926\n",
      "Epoch 52/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3770 - accuracy: 0.7942 - val_loss: 0.4133 - val_accuracy: 0.7766\n",
      "Epoch 53/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3544 - accuracy: 0.8181 - val_loss: 0.3881 - val_accuracy: 0.7819\n",
      "Epoch 54/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3470 - accuracy: 0.8393 - val_loss: 0.3572 - val_accuracy: 0.8564\n",
      "Epoch 55/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3502 - accuracy: 0.8287 - val_loss: 0.3672 - val_accuracy: 0.8457\n",
      "Epoch 56/120\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.3603 - accuracy: 0.8274 - val_loss: 0.3629 - val_accuracy: 0.8457\n",
      "Epoch 57/120\n",
      "24/24 [==============================] - 5s 226ms/step - loss: 0.3519 - accuracy: 0.8327 - val_loss: 0.4121 - val_accuracy: 0.8032\n",
      "Epoch 58/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3479 - accuracy: 0.8367 - val_loss: 0.4209 - val_accuracy: 0.8032\n",
      "Epoch 59/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3704 - accuracy: 0.8127 - val_loss: 0.3973 - val_accuracy: 0.7979\n",
      "Epoch 60/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3535 - accuracy: 0.8406 - val_loss: 0.4030 - val_accuracy: 0.8191\n",
      "Epoch 61/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3920 - accuracy: 0.8088 - val_loss: 0.4418 - val_accuracy: 0.7606\n",
      "Epoch 62/120\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.3636 - accuracy: 0.8274 - val_loss: 0.3732 - val_accuracy: 0.8085\n",
      "Epoch 63/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3721 - accuracy: 0.8061 - val_loss: 0.4131 - val_accuracy: 0.8032\n",
      "Epoch 64/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3576 - accuracy: 0.8141 - val_loss: 0.3643 - val_accuracy: 0.8351\n",
      "Epoch 65/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3418 - accuracy: 0.8327 - val_loss: 0.3864 - val_accuracy: 0.7926\n",
      "Epoch 66/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3452 - accuracy: 0.8446 - val_loss: 0.3696 - val_accuracy: 0.8245\n",
      "Epoch 67/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3366 - accuracy: 0.8260 - val_loss: 0.4237 - val_accuracy: 0.7926\n",
      "Epoch 68/120\n",
      "24/24 [==============================] - 5s 220ms/step - loss: 0.3646 - accuracy: 0.8313 - val_loss: 0.4597 - val_accuracy: 0.7553\n",
      "Epoch 69/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3808 - accuracy: 0.8154 - val_loss: 0.3853 - val_accuracy: 0.8085\n",
      "Epoch 70/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3503 - accuracy: 0.8313 - val_loss: 0.4185 - val_accuracy: 0.7926\n",
      "Epoch 71/120\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.3573 - accuracy: 0.8260 - val_loss: 0.4093 - val_accuracy: 0.7872\n",
      "Epoch 72/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3590 - accuracy: 0.8207 - val_loss: 0.4050 - val_accuracy: 0.7926\n",
      "Epoch 73/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3498 - accuracy: 0.8313 - val_loss: 0.3705 - val_accuracy: 0.8245\n",
      "Epoch 74/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3492 - accuracy: 0.8247 - val_loss: 0.4064 - val_accuracy: 0.8138\n",
      "Epoch 75/120\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.3425 - accuracy: 0.8393 - val_loss: 0.4226 - val_accuracy: 0.7872\n",
      "Epoch 76/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3643 - accuracy: 0.8154 - val_loss: 0.3711 - val_accuracy: 0.8138\n",
      "Epoch 77/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3557 - accuracy: 0.8300 - val_loss: 0.3813 - val_accuracy: 0.7979\n",
      "Epoch 78/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3450 - accuracy: 0.8220 - val_loss: 0.3637 - val_accuracy: 0.8191\n",
      "Epoch 79/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3464 - accuracy: 0.8353 - val_loss: 0.3329 - val_accuracy: 0.8564\n",
      "Epoch 80/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3838 - accuracy: 0.8101 - val_loss: 0.4063 - val_accuracy: 0.8351\n",
      "Epoch 81/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3482 - accuracy: 0.8300 - val_loss: 0.4070 - val_accuracy: 0.8404\n",
      "Epoch 82/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3334 - accuracy: 0.8539 - val_loss: 0.3855 - val_accuracy: 0.8191\n",
      "Epoch 83/120\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.3270 - accuracy: 0.8353 - val_loss: 0.3807 - val_accuracy: 0.8032\n",
      "Epoch 84/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3162 - accuracy: 0.8619 - val_loss: 0.3716 - val_accuracy: 0.7926\n",
      "Epoch 85/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3263 - accuracy: 0.8393 - val_loss: 0.3519 - val_accuracy: 0.8138\n",
      "Epoch 86/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3373 - accuracy: 0.8234 - val_loss: 0.3768 - val_accuracy: 0.8351\n",
      "Epoch 87/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3505 - accuracy: 0.8380 - val_loss: 0.4659 - val_accuracy: 0.7819\n",
      "Epoch 88/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3290 - accuracy: 0.8274 - val_loss: 0.3638 - val_accuracy: 0.8457\n",
      "Epoch 89/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3359 - accuracy: 0.8433 - val_loss: 0.3718 - val_accuracy: 0.8245\n",
      "Epoch 90/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3388 - accuracy: 0.8380 - val_loss: 0.3504 - val_accuracy: 0.8351\n",
      "Epoch 91/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3508 - accuracy: 0.8167 - val_loss: 0.3822 - val_accuracy: 0.8032\n",
      "Epoch 92/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3526 - accuracy: 0.8367 - val_loss: 0.3908 - val_accuracy: 0.7766\n",
      "Epoch 93/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3231 - accuracy: 0.8473 - val_loss: 0.3277 - val_accuracy: 0.8457\n",
      "Epoch 94/120\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.3604 - accuracy: 0.8167 - val_loss: 0.4102 - val_accuracy: 0.8085\n",
      "Epoch 95/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3732 - accuracy: 0.8181 - val_loss: 0.3301 - val_accuracy: 0.8511\n",
      "Epoch 96/120\n",
      "24/24 [==============================] - 5s 225ms/step - loss: 0.3228 - accuracy: 0.8579 - val_loss: 0.3790 - val_accuracy: 0.8351\n",
      "Epoch 97/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3325 - accuracy: 0.8353 - val_loss: 0.3307 - val_accuracy: 0.8457\n",
      "Epoch 98/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3285 - accuracy: 0.8459 - val_loss: 0.3419 - val_accuracy: 0.8404\n",
      "Epoch 99/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3335 - accuracy: 0.8274 - val_loss: 0.3695 - val_accuracy: 0.8351\n",
      "Epoch 100/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3309 - accuracy: 0.8300 - val_loss: 0.3529 - val_accuracy: 0.8245\n",
      "Epoch 101/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3167 - accuracy: 0.8459 - val_loss: 0.3359 - val_accuracy: 0.8511\n",
      "Epoch 102/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3378 - accuracy: 0.8327 - val_loss: 0.3538 - val_accuracy: 0.8351\n",
      "Epoch 103/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3178 - accuracy: 0.8513 - val_loss: 0.3261 - val_accuracy: 0.8457\n",
      "Epoch 104/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3267 - accuracy: 0.8353 - val_loss: 0.3822 - val_accuracy: 0.7979\n",
      "Epoch 105/120\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.3121 - accuracy: 0.8446 - val_loss: 0.3673 - val_accuracy: 0.8670\n",
      "Epoch 106/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3355 - accuracy: 0.8313 - val_loss: 0.4152 - val_accuracy: 0.8245\n",
      "Epoch 107/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3068 - accuracy: 0.8459 - val_loss: 0.3443 - val_accuracy: 0.8457\n",
      "Epoch 108/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3168 - accuracy: 0.8513 - val_loss: 0.3690 - val_accuracy: 0.8457\n",
      "Epoch 109/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3324 - accuracy: 0.8380 - val_loss: 0.3294 - val_accuracy: 0.8245\n",
      "Epoch 110/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3186 - accuracy: 0.8473 - val_loss: 0.3776 - val_accuracy: 0.8191\n",
      "Epoch 111/120\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.3244 - accuracy: 0.8513 - val_loss: 0.3491 - val_accuracy: 0.8511\n",
      "Epoch 112/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3308 - accuracy: 0.8513 - val_loss: 0.3597 - val_accuracy: 0.8351\n",
      "Epoch 113/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3166 - accuracy: 0.8606 - val_loss: 0.3486 - val_accuracy: 0.8457\n",
      "Epoch 114/120\n",
      "24/24 [==============================] - 5s 221ms/step - loss: 0.3158 - accuracy: 0.8539 - val_loss: 0.3427 - val_accuracy: 0.8617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3152 - accuracy: 0.8380 - val_loss: 0.3748 - val_accuracy: 0.8351\n",
      "Epoch 116/120\n",
      "24/24 [==============================] - 6s 229ms/step - loss: 0.3257 - accuracy: 0.8619 - val_loss: 0.3344 - val_accuracy: 0.8670\n",
      "Epoch 117/120\n",
      "24/24 [==============================] - 6s 234ms/step - loss: 0.3058 - accuracy: 0.8606 - val_loss: 0.3423 - val_accuracy: 0.8404\n",
      "Epoch 118/120\n",
      "24/24 [==============================] - 5s 222ms/step - loss: 0.3062 - accuracy: 0.8566 - val_loss: 0.3667 - val_accuracy: 0.8564\n",
      "Epoch 119/120\n",
      "24/24 [==============================] - 5s 224ms/step - loss: 0.3083 - accuracy: 0.8526 - val_loss: 0.3077 - val_accuracy: 0.8670\n",
      "Epoch 120/120\n",
      "24/24 [==============================] - 5s 223ms/step - loss: 0.3108 - accuracy: 0.8645 - val_loss: 0.3949 - val_accuracy: 0.7872\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "#x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=120,\n",
    "    #callbacks=[\n",
    "     #   tf.keras.callbacks.EarlyStopping(\n",
    "      #      monitor='val_loss',\n",
    "       #     patience=5,\n",
    "        #    restore_best_weights=True\n",
    "       # ),\n",
    "       # tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        #    monitor='val_loss',\n",
    "         #   patience=3\n",
    "       # )\n",
    "    #]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8510177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test loss: 0.30493\n",
      "test accuracy: 84.65%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_images, verbose = 0)\n",
    "print(\"  test loss: {:.5f}\".format(results[0]))\n",
    "print(\"test accuracy: {:.2f}%\".format(results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd2b5ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/13 [========>.....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 14:20:15.689792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/2390734351.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predictions = (model.predict(test_images) >= 0.5).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "----------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76       123\n",
      "           1       0.90      0.87      0.89       281\n",
      "\n",
      "    accuracy                           0.85       404\n",
      "   macro avg       0.82      0.83      0.82       404\n",
      "weighted avg       0.85      0.85      0.85       404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(test_images) >= 0.5).astype(np.int)\n",
    "\n",
    "cm = confusion_matrix(test_images.labels, predictions, labels=[0, 1])\n",
    "clr = classification_report(test_images.labels, predictions, labels=[0, 1], target_names=[\"0\", \"1\"])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=[\"0\", \"1\"])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=[\"0\", \"1\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca21af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d158d44e-6e45-4263-952a-204be19b05a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = Path('/Users/geek/Downloads/geek/liver/00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "290600d6-aa43-4c10-84cd-fb84ce646ce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "labels = list(map(lambda x: '0', filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "zerosimage_df = pd.concat([filepaths, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32c36ec7-6b6c-4858-bfb1-ce2d591fa8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir2 = Path('/Users/geek/Downloads/geek/liver/11')\n",
    "filepaths2 = list(image_dir2.glob(r'**/*.png'))\n",
    "labels2 = list(map(lambda x: '1', filepaths2))\n",
    "\n",
    "filepaths2 = pd.Series(filepaths2, name='Filepath').astype(str)\n",
    "labels2 = pd.Series(labels2, name='Label')\n",
    "\n",
    "onesimage_df = pd.concat([filepaths2, labels2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0f95e71-e2aa-4e92-ba32-902b7e72796a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/geek/Downloads/geek/liver/00/_png/20161012_185527_MR_/8_1.png'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zerosimage_df[\"Filepath\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55991785-0f11-4422-be23-3244941ad641",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1344 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filepath Label\n",
       "0     /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "1     /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "2     /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "3     /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "4     /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "...                                                 ...   ...\n",
       "1339  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "1340  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "1341  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "1342  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "1343  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "\n",
       "[1344 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onesimage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb1c75d0-1105-4d2c-ba6f-4b93404dbd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df1 = [zerosimage_df,onesimage_df]\n",
    "image_df = pd.concat(image_df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4801316-ef7f-4707-825d-066da62f6e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/00/_png/20161...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/00/_png/20161...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/00/_png/20161...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/00/_png/20161...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/00/_png/20161...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filepath Label\n",
       "0     /Users/geek/Downloads/geek/liver/00/_png/20161...     0\n",
       "1     /Users/geek/Downloads/geek/liver/00/_png/20161...     0\n",
       "2     /Users/geek/Downloads/geek/liver/00/_png/20161...     0\n",
       "3     /Users/geek/Downloads/geek/liver/00/_png/20161...     0\n",
       "4     /Users/geek/Downloads/geek/liver/00/_png/20161...     0\n",
       "...                                                 ...   ...\n",
       "1339  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "1340  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "1341  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "1342  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "1343  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "\n",
       "[1776 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a93ce0d-8784-4e16-8d18-3e12db6ba8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = train_test_split(image_df,train_size=0.7, shuffle = True , random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3944d9cb-9925-40e1-b408-7f63681f4ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/00/_png/20161...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20170...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20161...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/00/_png/20161...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1243 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filepath Label\n",
       "988   /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "426   /Users/geek/Downloads/geek/liver/00/_png/20161...     0\n",
       "810   /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "968   /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "1074  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "...                                                 ...   ...\n",
       "283   /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "473   /Users/geek/Downloads/geek/liver/11/_png/20170...     1\n",
       "664   /Users/geek/Downloads/geek/liver/11/_png/20161...     1\n",
       "235   /Users/geek/Downloads/geek/liver/00/_png/20161...     0\n",
       "629   /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "\n",
       "[1243 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6744a6a0-be95-4284-b904-2d75000ae589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20161...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/00/_png/20161...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/00/_png/20161...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20161...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20160...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/00/_png/20161...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>/Users/geek/Downloads/geek/liver/11/_png/20161...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>533 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Filepath Label\n",
       "720   /Users/geek/Downloads/geek/liver/11/_png/20161...     1\n",
       "1254  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "302   /Users/geek/Downloads/geek/liver/00/_png/20161...     0\n",
       "108   /Users/geek/Downloads/geek/liver/00/_png/20161...     0\n",
       "1185  /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "...                                                 ...   ...\n",
       "992   /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "709   /Users/geek/Downloads/geek/liver/11/_png/20161...     1\n",
       "105   /Users/geek/Downloads/geek/liver/11/_png/20160...     1\n",
       "314   /Users/geek/Downloads/geek/liver/00/_png/20161...     0\n",
       "336   /Users/geek/Downloads/geek/liver/11/_png/20161...     1\n",
       "\n",
       "[533 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba3aec-4134-4333-835e-00f084498d6c",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe92363d-43ed-422c-94c2-0afcef6264bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab7357d4-0eeb-41f0-a0e0-4cb7d5e3de6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 995 validated image filenames belonging to 2 classes.\n",
      "Found 248 validated image filenames belonging to 2 classes.\n",
      "Found 533 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ad8a01-0ab8-4bb8-af6a-70de9d4709f0",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6e0c38f-845f-41cc-a92d-21d20ca05e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 14:20:16.761663: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.7578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 14:20:22.399142: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 7s 213ms/step - loss: 0.6173 - accuracy: 0.7578 - val_loss: 0.6016 - val_accuracy: 0.7500\n",
      "Epoch 2/120\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 0.5721 - accuracy: 0.7578 - val_loss: 0.5676 - val_accuracy: 0.7500\n",
      "Epoch 3/120\n",
      "32/32 [==============================] - 7s 206ms/step - loss: 0.5486 - accuracy: 0.7578 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 4/120\n",
      "32/32 [==============================] - 7s 205ms/step - loss: 0.5317 - accuracy: 0.7578 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 5/120\n",
      "32/32 [==============================] - 7s 205ms/step - loss: 0.5185 - accuracy: 0.7578 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
      "Epoch 6/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.4923 - accuracy: 0.7578 - val_loss: 0.4837 - val_accuracy: 0.7540\n",
      "Epoch 7/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.4444 - accuracy: 0.7809 - val_loss: 0.4209 - val_accuracy: 0.7903\n",
      "Epoch 8/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.4212 - accuracy: 0.7789 - val_loss: 0.4081 - val_accuracy: 0.7903\n",
      "Epoch 9/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.4002 - accuracy: 0.8010 - val_loss: 0.3821 - val_accuracy: 0.8226\n",
      "Epoch 10/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.4008 - accuracy: 0.8080 - val_loss: 0.3966 - val_accuracy: 0.8065\n",
      "Epoch 11/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.4037 - accuracy: 0.8030 - val_loss: 0.4149 - val_accuracy: 0.8065\n",
      "Epoch 12/120\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.3953 - accuracy: 0.7960 - val_loss: 0.4147 - val_accuracy: 0.7661\n",
      "Epoch 13/120\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.3914 - accuracy: 0.8050 - val_loss: 0.4399 - val_accuracy: 0.7540\n",
      "Epoch 14/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.4060 - accuracy: 0.7970 - val_loss: 0.3908 - val_accuracy: 0.7903\n",
      "Epoch 15/120\n",
      "32/32 [==============================] - 7s 202ms/step - loss: 0.4012 - accuracy: 0.7970 - val_loss: 0.3877 - val_accuracy: 0.7863\n",
      "Epoch 16/120\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.3851 - accuracy: 0.7869 - val_loss: 0.4269 - val_accuracy: 0.7702\n",
      "Epoch 17/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.3736 - accuracy: 0.7970 - val_loss: 0.3890 - val_accuracy: 0.8347\n",
      "Epoch 18/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.3954 - accuracy: 0.7950 - val_loss: 0.3779 - val_accuracy: 0.7984\n",
      "Epoch 19/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.3683 - accuracy: 0.8101 - val_loss: 0.3849 - val_accuracy: 0.8306\n",
      "Epoch 20/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.3747 - accuracy: 0.8181 - val_loss: 0.4102 - val_accuracy: 0.8024\n",
      "Epoch 21/120\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.3721 - accuracy: 0.8040 - val_loss: 0.3672 - val_accuracy: 0.8266\n",
      "Epoch 22/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.3705 - accuracy: 0.7980 - val_loss: 0.3715 - val_accuracy: 0.7944\n",
      "Epoch 23/120\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 0.3576 - accuracy: 0.8101 - val_loss: 0.4048 - val_accuracy: 0.8024\n",
      "Epoch 24/120\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 0.3733 - accuracy: 0.7920 - val_loss: 0.3764 - val_accuracy: 0.8185\n",
      "Epoch 25/120\n",
      "32/32 [==============================] - 7s 206ms/step - loss: 0.3616 - accuracy: 0.8090 - val_loss: 0.3683 - val_accuracy: 0.8185\n",
      "Epoch 26/120\n",
      "32/32 [==============================] - 8s 235ms/step - loss: 0.3567 - accuracy: 0.8131 - val_loss: 0.3619 - val_accuracy: 0.8306\n",
      "Epoch 27/120\n",
      "32/32 [==============================] - 7s 221ms/step - loss: 0.3611 - accuracy: 0.8121 - val_loss: 0.3935 - val_accuracy: 0.8065\n",
      "Epoch 28/120\n",
      "32/32 [==============================] - 7s 217ms/step - loss: 0.3610 - accuracy: 0.8101 - val_loss: 0.3484 - val_accuracy: 0.8145\n",
      "Epoch 29/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.3585 - accuracy: 0.8181 - val_loss: 0.3321 - val_accuracy: 0.8508\n",
      "Epoch 30/120\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.3541 - accuracy: 0.8171 - val_loss: 0.3638 - val_accuracy: 0.8105\n",
      "Epoch 31/120\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.3438 - accuracy: 0.8251 - val_loss: 0.3448 - val_accuracy: 0.8508\n",
      "Epoch 32/120\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.3457 - accuracy: 0.8261 - val_loss: 0.3734 - val_accuracy: 0.7944\n",
      "Epoch 33/120\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.3459 - accuracy: 0.8181 - val_loss: 0.3379 - val_accuracy: 0.8427\n",
      "Epoch 34/120\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.3446 - accuracy: 0.8121 - val_loss: 0.3377 - val_accuracy: 0.8508\n",
      "Epoch 35/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.3297 - accuracy: 0.8312 - val_loss: 0.3616 - val_accuracy: 0.8306\n",
      "Epoch 36/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.3243 - accuracy: 0.8332 - val_loss: 0.3459 - val_accuracy: 0.8306\n",
      "Epoch 37/120\n",
      "32/32 [==============================] - 7s 205ms/step - loss: 0.3450 - accuracy: 0.8251 - val_loss: 0.3327 - val_accuracy: 0.8306\n",
      "Epoch 38/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.3239 - accuracy: 0.8332 - val_loss: 0.3246 - val_accuracy: 0.8629\n",
      "Epoch 39/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.3188 - accuracy: 0.8372 - val_loss: 0.3143 - val_accuracy: 0.8508\n",
      "Epoch 40/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.3424 - accuracy: 0.8251 - val_loss: 0.3138 - val_accuracy: 0.8387\n",
      "Epoch 41/120\n",
      "32/32 [==============================] - 7s 217ms/step - loss: 0.3183 - accuracy: 0.8352 - val_loss: 0.3277 - val_accuracy: 0.8306\n",
      "Epoch 42/120\n",
      "32/32 [==============================] - 7s 212ms/step - loss: 0.3137 - accuracy: 0.8372 - val_loss: 0.3271 - val_accuracy: 0.8427\n",
      "Epoch 43/120\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 0.3297 - accuracy: 0.8332 - val_loss: 0.3181 - val_accuracy: 0.8427\n",
      "Epoch 44/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.3146 - accuracy: 0.8261 - val_loss: 0.3098 - val_accuracy: 0.8589\n",
      "Epoch 45/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.3064 - accuracy: 0.8402 - val_loss: 0.3110 - val_accuracy: 0.8750\n",
      "Epoch 46/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.3107 - accuracy: 0.8533 - val_loss: 0.3117 - val_accuracy: 0.8629\n",
      "Epoch 47/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.3141 - accuracy: 0.8472 - val_loss: 0.3591 - val_accuracy: 0.8105\n",
      "Epoch 48/120\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.3037 - accuracy: 0.8442 - val_loss: 0.3010 - val_accuracy: 0.8669\n",
      "Epoch 49/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2928 - accuracy: 0.8513 - val_loss: 0.3043 - val_accuracy: 0.8508\n",
      "Epoch 50/120\n",
      "32/32 [==============================] - 7s 202ms/step - loss: 0.3224 - accuracy: 0.8412 - val_loss: 0.3076 - val_accuracy: 0.8548\n",
      "Epoch 51/120\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.3343 - accuracy: 0.8271 - val_loss: 0.2997 - val_accuracy: 0.8508\n",
      "Epoch 52/120\n",
      "32/32 [==============================] - 7s 208ms/step - loss: 0.3080 - accuracy: 0.8472 - val_loss: 0.3035 - val_accuracy: 0.8427\n",
      "Epoch 53/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2902 - accuracy: 0.8563 - val_loss: 0.2889 - val_accuracy: 0.8589\n",
      "Epoch 54/120\n",
      "32/32 [==============================] - 7s 210ms/step - loss: 0.2787 - accuracy: 0.8643 - val_loss: 0.2855 - val_accuracy: 0.8669\n",
      "Epoch 55/120\n",
      "32/32 [==============================] - 7s 205ms/step - loss: 0.2805 - accuracy: 0.8573 - val_loss: 0.3187 - val_accuracy: 0.8548\n",
      "Epoch 56/120\n",
      "32/32 [==============================] - 7s 207ms/step - loss: 0.2784 - accuracy: 0.8573 - val_loss: 0.2821 - val_accuracy: 0.8871\n",
      "Epoch 57/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2855 - accuracy: 0.8653 - val_loss: 0.2721 - val_accuracy: 0.8790\n",
      "Epoch 58/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2859 - accuracy: 0.8503 - val_loss: 0.2919 - val_accuracy: 0.8589\n",
      "Epoch 59/120\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.2829 - accuracy: 0.8633 - val_loss: 0.2794 - val_accuracy: 0.8710\n",
      "Epoch 60/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2841 - accuracy: 0.8643 - val_loss: 0.2818 - val_accuracy: 0.8790\n",
      "Epoch 61/120\n",
      "32/32 [==============================] - 7s 207ms/step - loss: 0.3083 - accuracy: 0.8402 - val_loss: 0.2835 - val_accuracy: 0.8629\n",
      "Epoch 62/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2762 - accuracy: 0.8583 - val_loss: 0.2869 - val_accuracy: 0.8669\n",
      "Epoch 63/120\n",
      "32/32 [==============================] - 7s 202ms/step - loss: 0.2673 - accuracy: 0.8673 - val_loss: 0.2738 - val_accuracy: 0.8750\n",
      "Epoch 64/120\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.2675 - accuracy: 0.8683 - val_loss: 0.2708 - val_accuracy: 0.8629\n",
      "Epoch 65/120\n",
      "32/32 [==============================] - 7s 202ms/step - loss: 0.2615 - accuracy: 0.8774 - val_loss: 0.2486 - val_accuracy: 0.8710\n",
      "Epoch 66/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2541 - accuracy: 0.8764 - val_loss: 0.2478 - val_accuracy: 0.9073\n",
      "Epoch 67/120\n",
      "32/32 [==============================] - 7s 202ms/step - loss: 0.2703 - accuracy: 0.8714 - val_loss: 0.2830 - val_accuracy: 0.8790\n",
      "Epoch 68/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2567 - accuracy: 0.8844 - val_loss: 0.2535 - val_accuracy: 0.8831\n",
      "Epoch 69/120\n",
      "32/32 [==============================] - 7s 202ms/step - loss: 0.2542 - accuracy: 0.8704 - val_loss: 0.2420 - val_accuracy: 0.9073\n",
      "Epoch 70/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2653 - accuracy: 0.8643 - val_loss: 0.2647 - val_accuracy: 0.8952\n",
      "Epoch 71/120\n",
      "32/32 [==============================] - 7s 211ms/step - loss: 0.2723 - accuracy: 0.8633 - val_loss: 0.2828 - val_accuracy: 0.8347\n",
      "Epoch 72/120\n",
      "32/32 [==============================] - 7s 212ms/step - loss: 0.2558 - accuracy: 0.8663 - val_loss: 0.2354 - val_accuracy: 0.8871\n",
      "Epoch 73/120\n",
      "32/32 [==============================] - 7s 220ms/step - loss: 0.2446 - accuracy: 0.8834 - val_loss: 0.2858 - val_accuracy: 0.8629\n",
      "Epoch 74/120\n",
      "32/32 [==============================] - 7s 209ms/step - loss: 0.2797 - accuracy: 0.8663 - val_loss: 0.2405 - val_accuracy: 0.9032\n",
      "Epoch 75/120\n",
      "32/32 [==============================] - 7s 210ms/step - loss: 0.2561 - accuracy: 0.8704 - val_loss: 0.2447 - val_accuracy: 0.8992\n",
      "Epoch 76/120\n",
      "32/32 [==============================] - 7s 210ms/step - loss: 0.2403 - accuracy: 0.8824 - val_loss: 0.2267 - val_accuracy: 0.8992\n",
      "Epoch 77/120\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 0.2478 - accuracy: 0.8834 - val_loss: 0.2418 - val_accuracy: 0.8911\n",
      "Epoch 78/120\n",
      "32/32 [==============================] - 7s 207ms/step - loss: 0.2378 - accuracy: 0.8935 - val_loss: 0.2383 - val_accuracy: 0.8911\n",
      "Epoch 79/120\n",
      "32/32 [==============================] - 7s 206ms/step - loss: 0.2361 - accuracy: 0.8874 - val_loss: 0.2568 - val_accuracy: 0.8790\n",
      "Epoch 80/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2297 - accuracy: 0.8975 - val_loss: 0.2604 - val_accuracy: 0.8911\n",
      "Epoch 81/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2214 - accuracy: 0.8864 - val_loss: 0.2461 - val_accuracy: 0.8831\n",
      "Epoch 82/120\n",
      "32/32 [==============================] - 7s 205ms/step - loss: 0.2288 - accuracy: 0.8884 - val_loss: 0.2439 - val_accuracy: 0.8871\n",
      "Epoch 83/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2641 - accuracy: 0.8643 - val_loss: 0.2291 - val_accuracy: 0.9032\n",
      "Epoch 84/120\n",
      "32/32 [==============================] - 7s 202ms/step - loss: 0.2437 - accuracy: 0.8764 - val_loss: 0.3945 - val_accuracy: 0.7823\n",
      "Epoch 85/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2845 - accuracy: 0.8673 - val_loss: 0.2661 - val_accuracy: 0.8750\n",
      "Epoch 86/120\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.2406 - accuracy: 0.8854 - val_loss: 0.2261 - val_accuracy: 0.8992\n",
      "Epoch 87/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2369 - accuracy: 0.8965 - val_loss: 0.2192 - val_accuracy: 0.9113\n",
      "Epoch 88/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2161 - accuracy: 0.8985 - val_loss: 0.2690 - val_accuracy: 0.8871\n",
      "Epoch 89/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2411 - accuracy: 0.8844 - val_loss: 0.2330 - val_accuracy: 0.9073\n",
      "Epoch 90/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2178 - accuracy: 0.9055 - val_loss: 0.2372 - val_accuracy: 0.8669\n",
      "Epoch 91/120\n",
      "32/32 [==============================] - 7s 205ms/step - loss: 0.2233 - accuracy: 0.8925 - val_loss: 0.2465 - val_accuracy: 0.8952\n",
      "Epoch 92/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2146 - accuracy: 0.8985 - val_loss: 0.2326 - val_accuracy: 0.8871\n",
      "Epoch 93/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2277 - accuracy: 0.8915 - val_loss: 0.2226 - val_accuracy: 0.9153\n",
      "Epoch 94/120\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.2117 - accuracy: 0.9055 - val_loss: 0.2977 - val_accuracy: 0.8508\n",
      "Epoch 95/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2190 - accuracy: 0.8965 - val_loss: 0.2599 - val_accuracy: 0.8710\n",
      "Epoch 96/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2127 - accuracy: 0.9045 - val_loss: 0.2344 - val_accuracy: 0.8871\n",
      "Epoch 97/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2203 - accuracy: 0.9015 - val_loss: 0.2502 - val_accuracy: 0.8790\n",
      "Epoch 98/120\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.2316 - accuracy: 0.8905 - val_loss: 0.2538 - val_accuracy: 0.8710\n",
      "Epoch 99/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2498 - accuracy: 0.8884 - val_loss: 0.3017 - val_accuracy: 0.8589\n",
      "Epoch 100/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2390 - accuracy: 0.8894 - val_loss: 0.3227 - val_accuracy: 0.8347\n",
      "Epoch 101/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2397 - accuracy: 0.8864 - val_loss: 0.2406 - val_accuracy: 0.9032\n",
      "Epoch 102/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2083 - accuracy: 0.9196 - val_loss: 0.2576 - val_accuracy: 0.8831\n",
      "Epoch 103/120\n",
      "32/32 [==============================] - 7s 202ms/step - loss: 0.2318 - accuracy: 0.8874 - val_loss: 0.2327 - val_accuracy: 0.8750\n",
      "Epoch 104/120\n",
      "32/32 [==============================] - 7s 205ms/step - loss: 0.2465 - accuracy: 0.8854 - val_loss: 0.2448 - val_accuracy: 0.8790\n",
      "Epoch 105/120\n",
      "32/32 [==============================] - 7s 211ms/step - loss: 0.1904 - accuracy: 0.9206 - val_loss: 0.2160 - val_accuracy: 0.8790\n",
      "Epoch 106/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2038 - accuracy: 0.9136 - val_loss: 0.2243 - val_accuracy: 0.9073\n",
      "Epoch 107/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.1940 - accuracy: 0.9176 - val_loss: 0.2186 - val_accuracy: 0.8952\n",
      "Epoch 108/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2063 - accuracy: 0.9005 - val_loss: 0.1843 - val_accuracy: 0.9315\n",
      "Epoch 109/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.1945 - accuracy: 0.9085 - val_loss: 0.2450 - val_accuracy: 0.8831\n",
      "Epoch 110/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.1956 - accuracy: 0.9136 - val_loss: 0.2495 - val_accuracy: 0.8790\n",
      "Epoch 111/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.1878 - accuracy: 0.9216 - val_loss: 0.1775 - val_accuracy: 0.9153\n",
      "Epoch 112/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.2090 - accuracy: 0.9055 - val_loss: 0.2262 - val_accuracy: 0.8911\n",
      "Epoch 113/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.2114 - accuracy: 0.9035 - val_loss: 0.2147 - val_accuracy: 0.8911\n",
      "Epoch 114/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.1967 - accuracy: 0.9065 - val_loss: 0.1967 - val_accuracy: 0.9355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/120\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.2006 - accuracy: 0.9075 - val_loss: 0.1979 - val_accuracy: 0.9073\n",
      "Epoch 116/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.1912 - accuracy: 0.9176 - val_loss: 0.2226 - val_accuracy: 0.8952\n",
      "Epoch 117/120\n",
      "32/32 [==============================] - 7s 204ms/step - loss: 0.1859 - accuracy: 0.9095 - val_loss: 0.2130 - val_accuracy: 0.8710\n",
      "Epoch 118/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.1668 - accuracy: 0.9327 - val_loss: 0.1986 - val_accuracy: 0.8992\n",
      "Epoch 119/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.1689 - accuracy: 0.9276 - val_loss: 0.2105 - val_accuracy: 0.8992\n",
      "Epoch 120/120\n",
      "32/32 [==============================] - 7s 203ms/step - loss: 0.1863 - accuracy: 0.9116 - val_loss: 0.2092 - val_accuracy: 0.9153\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "#x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model2 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model2.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=120,\n",
    "    #callbacks=[\n",
    "     #   tf.keras.callbacks.EarlyStopping(\n",
    "      #      monitor='val_loss',\n",
    "       #     patience=5,\n",
    "        #    restore_best_weights=True\n",
    "       # ),\n",
    "       # tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        #    monitor='val_loss',\n",
    "         #   patience=3\n",
    "       # )\n",
    "    #]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f6b5a92-531e-45eb-af03-daf7f8d26394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test loss: 0.19306\n",
      "test accuracy: 91.37%\n"
     ]
    }
   ],
   "source": [
    "results = model2.evaluate(test_images, verbose = 0)\n",
    "print(\"  test loss: {:.5f}\".format(results[0]))\n",
    "print(\"test accuracy: {:.2f}%\".format(results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0673f9b3-4669-4656-aeeb-1b1481e82c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/17 [===========>..................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 14:33:29.049373: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/2796210669.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  predictions = (model2.predict(test_images) >= 0.5).astype(np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "----------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81       129\n",
      "           1       0.92      0.97      0.94       404\n",
      "\n",
      "    accuracy                           0.91       533\n",
      "   macro avg       0.90      0.85      0.87       533\n",
      "weighted avg       0.91      0.91      0.91       533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = (model2.predict(test_images) >= 0.5).astype(np.int)\n",
    "\n",
    "cm = confusion_matrix(test_images.labels, predictions, labels=[0, 1])\n",
    "clr = classification_report(test_images.labels, predictions, labels=[0, 1], target_names=[\"0\", \"1\"])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=[\"0\", \"1\"])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=[\"0\", \"1\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ff96571-47ce-47c9-a816-377b48940214",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path('/Users/geek/Downloads/img0')\n",
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "labels = list(map(lambda x: '0', filepaths))\n",
    "\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "zerosimage_df = pd.concat([filepaths, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2dcc0c28-7795-470d-ad18-e688deb1d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir2 = Path('/Users/geek/Downloads/img1')\n",
    "filepaths2 = list(image_dir2.glob(r'**/*.png'))\n",
    "labels2 = list(map(lambda x: '1', filepaths2))\n",
    "\n",
    "filepaths2 = pd.Series(filepaths2, name='Filepath').astype(str)\n",
    "labels2 = pd.Series(labels2, name='Label')\n",
    "\n",
    "onesimage_df = pd.concat([filepaths2, labels2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "177f9415-9289-4872-9c66-120b943ed8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/geek/Downloads/img0/0/613_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/geek/Downloads/img0/0/1210_8.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/geek/Downloads/img0/0/512_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/geek/Downloads/img0/0/818_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/geek/Downloads/img0/0/1120_5.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>/Users/geek/Downloads/img1/1/378_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>/Users/geek/Downloads/img1/1/910_3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>/Users/geek/Downloads/img1/1/1210_5.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>/Users/geek/Downloads/img1/1/711_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>/Users/geek/Downloads/img1/1/2410_7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Filepath Label\n",
       "0      /Users/geek/Downloads/img0/0/613_2.png     0\n",
       "1     /Users/geek/Downloads/img0/0/1210_8.png     0\n",
       "2      /Users/geek/Downloads/img0/0/512_2.png     0\n",
       "3      /Users/geek/Downloads/img0/0/818_2.png     0\n",
       "4     /Users/geek/Downloads/img0/0/1120_5.png     0\n",
       "...                                       ...   ...\n",
       "2292   /Users/geek/Downloads/img1/1/378_8.png     1\n",
       "2293   /Users/geek/Downloads/img1/1/910_3.png     1\n",
       "2294  /Users/geek/Downloads/img1/1/1210_5.png     1\n",
       "2295   /Users/geek/Downloads/img1/1/711_8.png     1\n",
       "2296  /Users/geek/Downloads/img1/1/2410_7.png     1\n",
       "\n",
       "[3121 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df1 = [zerosimage_df,onesimage_df]\n",
    "image_df = pd.concat(image_df1)\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1bb9c-d70c-4863-a01a-aef695f4dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "models = [model, model2]\n",
    "model_input = Input(shape=(224, 224, 3))\n",
    "model_outputs = [model(model_input) for model in models]\n",
    "ensemble_output = Average()(model_outputs)\n",
    "ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2da549-e540-42a7-bfe8-ab531a3790d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ce451-28ec-4a66-ad02-d94e023bd8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = train_test_split(image_df,train_size=0.7, shuffle = True , random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99be49-6f6a-4816-8887-7a8dd39168d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9823e-d7a2-42b8-9c67-a413b6f0c568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fc1c6a-cfcd-492d-ba51-4c769d5e0c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c82e73-4ded-4589-9286-86f147d8fb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0063e8-e1c5-49b5-95d5-aab05382c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=ensemble_model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=120,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0198fc55-0ee2-4ec7-b11f-ca925b55764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ensemble_model.evaluate(test_images, verbose = 0)\n",
    "print(\"  test loss: {:.5f}\".format(results[0]))\n",
    "print(\"test accuracy: {:.2f}%\".format(results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5232f-d0d1-4f1b-9bc2-fe37d7d70046",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (ensemble_model.predict(test_images) >= 0.5).astype(np.int)\n",
    "\n",
    "cm = confusion_matrix(test_images.labels, predictions, labels=[0, 1])\n",
    "clr = classification_report(test_images.labels, predictions, labels=[0, 1], target_names=[\"0\", \"1\"])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=[\"0\", \"1\"])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=[\"0\", \"1\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9856c81f-5fa1-4561-bea1-1a098285a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.applications import ResNet50,ResNet101\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39dc2092-2276-4f79-a8ba-639e5294a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold , KFold ,RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b4dc437-b1b4-4515-8a4c-704207856860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/geek/Downloads/img0/0/613_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/geek/Downloads/img0/0/1210_8.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/geek/Downloads/img0/0/512_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/geek/Downloads/img0/0/818_2.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/geek/Downloads/img0/0/1120_5.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>/Users/geek/Downloads/img1/1/378_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>/Users/geek/Downloads/img1/1/910_3.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>/Users/geek/Downloads/img1/1/1210_5.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>/Users/geek/Downloads/img1/1/711_8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>/Users/geek/Downloads/img1/1/2410_7.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3121 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Filepath Label\n",
       "0      /Users/geek/Downloads/img0/0/613_2.png     0\n",
       "1     /Users/geek/Downloads/img0/0/1210_8.png     0\n",
       "2      /Users/geek/Downloads/img0/0/512_2.png     0\n",
       "3      /Users/geek/Downloads/img0/0/818_2.png     0\n",
       "4     /Users/geek/Downloads/img0/0/1120_5.png     0\n",
       "...                                       ...   ...\n",
       "2292   /Users/geek/Downloads/img1/1/378_8.png     1\n",
       "2293   /Users/geek/Downloads/img1/1/910_3.png     1\n",
       "2294  /Users/geek/Downloads/img1/1/1210_5.png     1\n",
       "2295   /Users/geek/Downloads/img1/1/711_8.png     1\n",
       "2296  /Users/geek/Downloads/img1/1/2410_7.png     1\n",
       "\n",
       "[3121 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5130ee87-f0fe-4248-95c4-1356595fa38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pred = []\n",
    "error = []\n",
    "data_kfold = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4d54d08-b952-47f7-8716-0b4e88f17ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_fold=[]\n",
    "loss_per_fold=[]\n",
    "models=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d254786-4363-47c3-a64a-92634fdf8cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = image_df.Label\n",
    "train_x = image_df.drop(['Label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "192ffc3a-8437-4650-b784-f0b8535f60e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "N_SPLIT = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8345009-c338-45f4-8881-15d76e43ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "294a38d0-8bbc-4e33-a1bc-42c56f07233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=N_SPLIT,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "299e0ee9-f39c-414e-a96b-b1db9cd54237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for keeping count of split we are executing\n",
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0df7cba-0d59-4307-97cf-8b475cb708a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    models = [model, model2]\n",
    "    model_input = Input(shape=(224, 224, 3))\n",
    "    model_outputs = [model(model_input) for model in models]\n",
    "    ensemble_output = Average()(model_outputs)\n",
    "    ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')\n",
    "\n",
    "    ensemble_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "#     model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84fe985b-78a8-4ffe-9869-61a66b2d2896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2675 validated image filenames belonging to 2 classes.\n",
      "Found 446 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_test.fit_generator( training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - 15s 173ms/step - loss: 0.3650 - accuracy: 0.8199 - val_loss: 0.3632 - val_accuracy: 0.8363\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3690 - accuracy: 0.8135 - val_loss: 0.3402 - val_accuracy: 0.8341\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.3576 - accuracy: 0.8161 - val_loss: 0.3287 - val_accuracy: 0.8453\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3591 - accuracy: 0.8180 - val_loss: 0.3339 - val_accuracy: 0.8430\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.3632 - accuracy: 0.8207 - val_loss: 0.3228 - val_accuracy: 0.8565\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.3421 - accuracy: 0.8328 - val_loss: 0.3240 - val_accuracy: 0.8341\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3489 - accuracy: 0.8252 - val_loss: 0.3336 - val_accuracy: 0.8498\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.3427 - accuracy: 0.8290 - val_loss: 0.3059 - val_accuracy: 0.8655\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3591 - accuracy: 0.8150 - val_loss: 0.3115 - val_accuracy: 0.8587\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3544 - accuracy: 0.8188 - val_loss: 0.3416 - val_accuracy: 0.8430\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.3539 - accuracy: 0.8248 - val_loss: 0.3127 - val_accuracy: 0.8565\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3469 - accuracy: 0.8305 - val_loss: 0.3079 - val_accuracy: 0.8565\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3336 - accuracy: 0.8343 - val_loss: 0.2941 - val_accuracy: 0.8655\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.3255 - accuracy: 0.8426 - val_loss: 0.2888 - val_accuracy: 0.8543\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3338 - accuracy: 0.8313 - val_loss: 0.3191 - val_accuracy: 0.8408\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 14s 174ms/step - loss: 0.3311 - accuracy: 0.8396 - val_loss: 0.2886 - val_accuracy: 0.8857\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3195 - accuracy: 0.8430 - val_loss: 0.2729 - val_accuracy: 0.8744\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.3322 - accuracy: 0.8381 - val_loss: 0.2751 - val_accuracy: 0.8767\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.3271 - accuracy: 0.8418 - val_loss: 0.2668 - val_accuracy: 0.8857\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3263 - accuracy: 0.8464 - val_loss: 0.3424 - val_accuracy: 0.8430\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.3197 - accuracy: 0.8468 - val_loss: 0.2634 - val_accuracy: 0.8901\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.3072 - accuracy: 0.8574 - val_loss: 0.2652 - val_accuracy: 0.8812\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3102 - accuracy: 0.8471 - val_loss: 0.2871 - val_accuracy: 0.8700\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2999 - accuracy: 0.8551 - val_loss: 0.2602 - val_accuracy: 0.8834\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3002 - accuracy: 0.8585 - val_loss: 0.2505 - val_accuracy: 0.8901\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.3052 - accuracy: 0.8558 - val_loss: 0.2438 - val_accuracy: 0.9013\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2948 - accuracy: 0.8642 - val_loss: 0.2421 - val_accuracy: 0.8879\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2860 - accuracy: 0.8649 - val_loss: 0.2369 - val_accuracy: 0.9103\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.3019 - accuracy: 0.8577 - val_loss: 0.2788 - val_accuracy: 0.8767\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2829 - accuracy: 0.8687 - val_loss: 0.2316 - val_accuracy: 0.9170\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2962 - accuracy: 0.8555 - val_loss: 0.2352 - val_accuracy: 0.9103\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2909 - accuracy: 0.8645 - val_loss: 0.2676 - val_accuracy: 0.8901\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.2765 - accuracy: 0.8702 - val_loss: 0.2318 - val_accuracy: 0.9058\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2760 - accuracy: 0.8717 - val_loss: 0.2403 - val_accuracy: 0.9058\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.2695 - accuracy: 0.8770 - val_loss: 0.2262 - val_accuracy: 0.9013\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2716 - accuracy: 0.8740 - val_loss: 0.2201 - val_accuracy: 0.9283\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2607 - accuracy: 0.8816 - val_loss: 0.2263 - val_accuracy: 0.9103\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2674 - accuracy: 0.8801 - val_loss: 0.2139 - val_accuracy: 0.9215\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2550 - accuracy: 0.8914 - val_loss: 0.2086 - val_accuracy: 0.9395\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.2692 - accuracy: 0.8721 - val_loss: 0.3091 - val_accuracy: 0.8520\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2506 - accuracy: 0.8948 - val_loss: 0.2057 - val_accuracy: 0.9260\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2566 - accuracy: 0.8857 - val_loss: 0.2955 - val_accuracy: 0.8632\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.2549 - accuracy: 0.8816 - val_loss: 0.1999 - val_accuracy: 0.9126\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.2422 - accuracy: 0.8933 - val_loss: 0.2326 - val_accuracy: 0.9126\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2506 - accuracy: 0.8842 - val_loss: 0.2175 - val_accuracy: 0.9283\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2507 - accuracy: 0.8827 - val_loss: 0.2038 - val_accuracy: 0.9058\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2247 - accuracy: 0.9043 - val_loss: 0.1879 - val_accuracy: 0.9305\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2196 - accuracy: 0.9077 - val_loss: 0.1890 - val_accuracy: 0.9193\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2228 - accuracy: 0.9084 - val_loss: 0.3029 - val_accuracy: 0.8565\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2214 - accuracy: 0.9020 - val_loss: 0.1814 - val_accuracy: 0.9283\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2291 - accuracy: 0.9001 - val_loss: 0.1870 - val_accuracy: 0.9238\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.2168 - accuracy: 0.9035 - val_loss: 0.1868 - val_accuracy: 0.9305\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.2195 - accuracy: 0.9065 - val_loss: 0.3396 - val_accuracy: 0.8475\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.2211 - accuracy: 0.9103 - val_loss: 0.1837 - val_accuracy: 0.9327\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.2126 - accuracy: 0.9100 - val_loss: 0.1853 - val_accuracy: 0.9238\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2140 - accuracy: 0.9069 - val_loss: 0.2513 - val_accuracy: 0.8991\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 174ms/step - loss: 0.2149 - accuracy: 0.9088 - val_loss: 0.1916 - val_accuracy: 0.9395\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.2197 - accuracy: 0.9069 - val_loss: 0.2023 - val_accuracy: 0.9283\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.2040 - accuracy: 0.9160 - val_loss: 0.1936 - val_accuracy: 0.9283\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.1930 - accuracy: 0.9149 - val_loss: 0.1790 - val_accuracy: 0.9327\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.1895 - accuracy: 0.9209 - val_loss: 0.2045 - val_accuracy: 0.9260\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.1964 - accuracy: 0.9198 - val_loss: 0.1688 - val_accuracy: 0.9260\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.2039 - accuracy: 0.9084 - val_loss: 0.2128 - val_accuracy: 0.9126\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.1898 - accuracy: 0.9213 - val_loss: 0.3182 - val_accuracy: 0.8543\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2192 - accuracy: 0.9096 - val_loss: 0.1804 - val_accuracy: 0.9238\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.1828 - accuracy: 0.9251 - val_loss: 0.3150 - val_accuracy: 0.8610\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.2163 - accuracy: 0.9107 - val_loss: 0.2498 - val_accuracy: 0.9013\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2099 - accuracy: 0.9096 - val_loss: 0.1832 - val_accuracy: 0.9081\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.1932 - accuracy: 0.9213 - val_loss: 0.1750 - val_accuracy: 0.9305\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.2202 - accuracy: 0.9054 - val_loss: 0.2179 - val_accuracy: 0.9170\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.1809 - accuracy: 0.9255 - val_loss: 0.1815 - val_accuracy: 0.9148\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.1890 - accuracy: 0.9270 - val_loss: 0.1835 - val_accuracy: 0.9372\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.1864 - accuracy: 0.9251 - val_loss: 0.2186 - val_accuracy: 0.9081\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.1935 - accuracy: 0.9141 - val_loss: 0.2448 - val_accuracy: 0.8991\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.1873 - accuracy: 0.9194 - val_loss: 0.1757 - val_accuracy: 0.9260\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.1923 - accuracy: 0.9134 - val_loss: 0.1718 - val_accuracy: 0.9372\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.1993 - accuracy: 0.9126 - val_loss: 0.2140 - val_accuracy: 0.9283\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.1825 - accuracy: 0.9232 - val_loss: 0.1678 - val_accuracy: 0.9327\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.1857 - accuracy: 0.9205 - val_loss: 0.1841 - val_accuracy: 0.9260\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1774 - accuracy: 0.9262 - val_loss: 0.2228 - val_accuracy: 0.9126\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1902 - accuracy: 0.9232 - val_loss: 0.1681 - val_accuracy: 0.9395\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.1859 - accuracy: 0.9217 - val_loss: 0.1812 - val_accuracy: 0.9238\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.1706 - accuracy: 0.9277 - val_loss: 0.2201 - val_accuracy: 0.9126\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.1715 - accuracy: 0.9308 - val_loss: 0.1625 - val_accuracy: 0.9372\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1706 - accuracy: 0.9308 - val_loss: 0.1627 - val_accuracy: 0.9238\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.1793 - accuracy: 0.9289 - val_loss: 0.1985 - val_accuracy: 0.9170\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1793 - accuracy: 0.9266 - val_loss: 0.2705 - val_accuracy: 0.8722\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.1838 - accuracy: 0.9213 - val_loss: 0.1577 - val_accuracy: 0.9417\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.1809 - accuracy: 0.9277 - val_loss: 0.2420 - val_accuracy: 0.8901\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.1647 - accuracy: 0.9308 - val_loss: 0.1520 - val_accuracy: 0.9395\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1634 - accuracy: 0.9308 - val_loss: 0.1490 - val_accuracy: 0.9417\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 16s 190ms/step - loss: 0.1812 - accuracy: 0.9274 - val_loss: 0.2331 - val_accuracy: 0.9081\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 15s 182ms/step - loss: 0.1614 - accuracy: 0.9322 - val_loss: 0.2049 - val_accuracy: 0.9103\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1663 - accuracy: 0.9368 - val_loss: 0.1662 - val_accuracy: 0.9417\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1628 - accuracy: 0.9334 - val_loss: 0.1651 - val_accuracy: 0.9372\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1693 - accuracy: 0.9247 - val_loss: 0.1807 - val_accuracy: 0.9417\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 15s 182ms/step - loss: 0.1672 - accuracy: 0.9274 - val_loss: 0.1594 - val_accuracy: 0.9417\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1620 - accuracy: 0.9345 - val_loss: 0.1565 - val_accuracy: 0.9439\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1751 - accuracy: 0.9296 - val_loss: 0.1706 - val_accuracy: 0.9372\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1695 - accuracy: 0.9304 - val_loss: 0.1481 - val_accuracy: 0.9439\n",
      "Found 3121 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:34: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred= model_test.predict_generator(test_set, len(image_df) // 32)\n",
      "2022-12-28 15:04:09.361682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 0.1552063226699829; accuracy of 93.24578046798706%\n",
      "Found 2675 validated image filenames belonging to 2 classes.\n",
      "Found 446 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_test.fit_generator( training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1727 - accuracy: 0.9304 - val_loss: 0.2089 - val_accuracy: 0.9260\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1504 - accuracy: 0.9414 - val_loss: 0.1930 - val_accuracy: 0.9238\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1879 - accuracy: 0.9217 - val_loss: 0.2070 - val_accuracy: 0.9238\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1605 - accuracy: 0.9319 - val_loss: 0.1563 - val_accuracy: 0.9417\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1610 - accuracy: 0.9345 - val_loss: 0.1684 - val_accuracy: 0.9170\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1580 - accuracy: 0.9342 - val_loss: 0.3276 - val_accuracy: 0.8632\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1646 - accuracy: 0.9296 - val_loss: 0.2156 - val_accuracy: 0.9103\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1534 - accuracy: 0.9398 - val_loss: 0.2408 - val_accuracy: 0.8969\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1622 - accuracy: 0.9315 - val_loss: 0.1956 - val_accuracy: 0.9148\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1571 - accuracy: 0.9364 - val_loss: 0.1853 - val_accuracy: 0.9260\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1678 - accuracy: 0.9327 - val_loss: 0.1809 - val_accuracy: 0.9215\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1728 - accuracy: 0.9243 - val_loss: 0.1875 - val_accuracy: 0.9260\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.1780 - accuracy: 0.9194 - val_loss: 0.1580 - val_accuracy: 0.9462\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1678 - accuracy: 0.9274 - val_loss: 0.1550 - val_accuracy: 0.9395\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1489 - accuracy: 0.9391 - val_loss: 0.1521 - val_accuracy: 0.9417\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1705 - accuracy: 0.9270 - val_loss: 0.2547 - val_accuracy: 0.9013\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1543 - accuracy: 0.9387 - val_loss: 0.1600 - val_accuracy: 0.9395\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1593 - accuracy: 0.9345 - val_loss: 0.1482 - val_accuracy: 0.9439\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1743 - accuracy: 0.9281 - val_loss: 0.1738 - val_accuracy: 0.9260\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 15s 183ms/step - loss: 0.1458 - accuracy: 0.9429 - val_loss: 0.1763 - val_accuracy: 0.9260\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 15s 182ms/step - loss: 0.1473 - accuracy: 0.9383 - val_loss: 0.1888 - val_accuracy: 0.9215\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1571 - accuracy: 0.9387 - val_loss: 0.1461 - val_accuracy: 0.9507\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1537 - accuracy: 0.9387 - val_loss: 0.1992 - val_accuracy: 0.9170\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1653 - accuracy: 0.9334 - val_loss: 0.1371 - val_accuracy: 0.9507\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1444 - accuracy: 0.9421 - val_loss: 0.1448 - val_accuracy: 0.9574\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1494 - accuracy: 0.9383 - val_loss: 0.1332 - val_accuracy: 0.9529\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1409 - accuracy: 0.9467 - val_loss: 0.1625 - val_accuracy: 0.9305\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1378 - accuracy: 0.9429 - val_loss: 0.1494 - val_accuracy: 0.9507\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1429 - accuracy: 0.9425 - val_loss: 0.1388 - val_accuracy: 0.9552\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1458 - accuracy: 0.9429 - val_loss: 0.2685 - val_accuracy: 0.9013\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1528 - accuracy: 0.9353 - val_loss: 0.1692 - val_accuracy: 0.9372\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1532 - accuracy: 0.9372 - val_loss: 0.1493 - val_accuracy: 0.9439\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1540 - accuracy: 0.9372 - val_loss: 0.1570 - val_accuracy: 0.9395\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1583 - accuracy: 0.9353 - val_loss: 0.1856 - val_accuracy: 0.9215\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1527 - accuracy: 0.9379 - val_loss: 0.1390 - val_accuracy: 0.9439\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1588 - accuracy: 0.9417 - val_loss: 0.1638 - val_accuracy: 0.9395\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1577 - accuracy: 0.9357 - val_loss: 0.1507 - val_accuracy: 0.9350\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1469 - accuracy: 0.9410 - val_loss: 0.1432 - val_accuracy: 0.9507\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1551 - accuracy: 0.9361 - val_loss: 0.1817 - val_accuracy: 0.9283\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1535 - accuracy: 0.9345 - val_loss: 0.1434 - val_accuracy: 0.9484\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1504 - accuracy: 0.9410 - val_loss: 0.1711 - val_accuracy: 0.9260\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1421 - accuracy: 0.9429 - val_loss: 0.1396 - val_accuracy: 0.9462\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1368 - accuracy: 0.9474 - val_loss: 0.1456 - val_accuracy: 0.9417\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1367 - accuracy: 0.9444 - val_loss: 0.1345 - val_accuracy: 0.9484\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1407 - accuracy: 0.9391 - val_loss: 0.2376 - val_accuracy: 0.9013\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1670 - accuracy: 0.9308 - val_loss: 0.1880 - val_accuracy: 0.9193\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1459 - accuracy: 0.9436 - val_loss: 0.1749 - val_accuracy: 0.9305\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1399 - accuracy: 0.9478 - val_loss: 0.1232 - val_accuracy: 0.9552\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1563 - accuracy: 0.9338 - val_loss: 0.1402 - val_accuracy: 0.9439\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.1443 - accuracy: 0.9463 - val_loss: 0.1856 - val_accuracy: 0.9148\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1498 - accuracy: 0.9368 - val_loss: 0.2231 - val_accuracy: 0.9170\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1591 - accuracy: 0.9357 - val_loss: 0.1740 - val_accuracy: 0.9283\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1523 - accuracy: 0.9342 - val_loss: 0.1817 - val_accuracy: 0.9327\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1427 - accuracy: 0.9410 - val_loss: 0.1394 - val_accuracy: 0.9484\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1369 - accuracy: 0.9501 - val_loss: 0.1574 - val_accuracy: 0.9462\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1450 - accuracy: 0.9410 - val_loss: 0.1436 - val_accuracy: 0.9552\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1342 - accuracy: 0.9436 - val_loss: 0.1641 - val_accuracy: 0.9372\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1408 - accuracy: 0.9504 - val_loss: 0.1425 - val_accuracy: 0.9507\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1576 - accuracy: 0.9368 - val_loss: 0.2446 - val_accuracy: 0.9036\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1462 - accuracy: 0.9367 - val_loss: 0.1500 - val_accuracy: 0.9350\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1321 - accuracy: 0.9501 - val_loss: 0.1882 - val_accuracy: 0.9193\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1327 - accuracy: 0.9508 - val_loss: 0.2752 - val_accuracy: 0.8879\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1484 - accuracy: 0.9349 - val_loss: 0.1606 - val_accuracy: 0.9395\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1339 - accuracy: 0.9501 - val_loss: 0.1399 - val_accuracy: 0.9439\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1350 - accuracy: 0.9425 - val_loss: 0.1398 - val_accuracy: 0.9417\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1560 - accuracy: 0.9353 - val_loss: 0.2477 - val_accuracy: 0.8991\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1351 - accuracy: 0.9467 - val_loss: 0.1772 - val_accuracy: 0.9238\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1415 - accuracy: 0.9421 - val_loss: 0.3054 - val_accuracy: 0.8857\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1666 - accuracy: 0.9285 - val_loss: 0.2201 - val_accuracy: 0.9058\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1362 - accuracy: 0.9459 - val_loss: 0.1503 - val_accuracy: 0.9395\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1480 - accuracy: 0.9402 - val_loss: 0.1309 - val_accuracy: 0.9507\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1406 - accuracy: 0.9444 - val_loss: 0.2330 - val_accuracy: 0.9103\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1348 - accuracy: 0.9448 - val_loss: 0.1464 - val_accuracy: 0.9507\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1368 - accuracy: 0.9451 - val_loss: 0.1928 - val_accuracy: 0.9170\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1497 - accuracy: 0.9391 - val_loss: 0.1333 - val_accuracy: 0.9507\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1456 - accuracy: 0.9391 - val_loss: 0.1416 - val_accuracy: 0.9439\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1320 - accuracy: 0.9478 - val_loss: 0.2614 - val_accuracy: 0.8946\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1563 - accuracy: 0.9444 - val_loss: 0.1729 - val_accuracy: 0.9417\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1296 - accuracy: 0.9516 - val_loss: 0.1501 - val_accuracy: 0.9462\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1326 - accuracy: 0.9497 - val_loss: 0.1247 - val_accuracy: 0.9507\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1363 - accuracy: 0.9440 - val_loss: 0.1609 - val_accuracy: 0.9327\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1239 - accuracy: 0.9485 - val_loss: 0.1347 - val_accuracy: 0.9552\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1401 - accuracy: 0.9410 - val_loss: 0.1330 - val_accuracy: 0.9484\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1377 - accuracy: 0.9463 - val_loss: 0.1923 - val_accuracy: 0.9148\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1180 - accuracy: 0.9610 - val_loss: 0.2209 - val_accuracy: 0.9148\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1285 - accuracy: 0.9504 - val_loss: 0.2174 - val_accuracy: 0.9103\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1320 - accuracy: 0.9474 - val_loss: 0.1280 - val_accuracy: 0.9529\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1430 - accuracy: 0.9421 - val_loss: 0.2568 - val_accuracy: 0.9013\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1313 - accuracy: 0.9493 - val_loss: 0.1589 - val_accuracy: 0.9305\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1327 - accuracy: 0.9478 - val_loss: 0.2152 - val_accuracy: 0.9126\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1314 - accuracy: 0.9478 - val_loss: 0.1537 - val_accuracy: 0.9417\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1463 - accuracy: 0.9414 - val_loss: 0.1827 - val_accuracy: 0.9215\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1270 - accuracy: 0.9516 - val_loss: 0.1775 - val_accuracy: 0.9260\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1324 - accuracy: 0.9478 - val_loss: 0.1520 - val_accuracy: 0.9327\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1355 - accuracy: 0.9459 - val_loss: 0.1197 - val_accuracy: 0.9507\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1361 - accuracy: 0.9448 - val_loss: 0.1904 - val_accuracy: 0.9170\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1235 - accuracy: 0.9489 - val_loss: 0.1620 - val_accuracy: 0.9395\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1226 - accuracy: 0.9569 - val_loss: 0.2032 - val_accuracy: 0.9103\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1323 - accuracy: 0.9451 - val_loss: 0.1518 - val_accuracy: 0.9350\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1211 - accuracy: 0.9538 - val_loss: 0.1710 - val_accuracy: 0.9193\n",
      "Found 3121 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:34: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred= model_test.predict_generator(test_set, len(image_df) // 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 0.17134647071361542; accuracy of 92.49531030654907%\n",
      "Found 2675 validated image filenames belonging to 2 classes.\n",
      "Found 446 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_test.fit_generator( training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1209 - accuracy: 0.9523 - val_loss: 0.2548 - val_accuracy: 0.8901\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1471 - accuracy: 0.9406 - val_loss: 0.1536 - val_accuracy: 0.9372\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1257 - accuracy: 0.9482 - val_loss: 0.1239 - val_accuracy: 0.9574\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.1397 - accuracy: 0.9414 - val_loss: 0.1948 - val_accuracy: 0.9215\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1204 - accuracy: 0.9523 - val_loss: 0.1242 - val_accuracy: 0.9439\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1304 - accuracy: 0.9512 - val_loss: 0.1842 - val_accuracy: 0.9260\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1215 - accuracy: 0.9519 - val_loss: 0.1249 - val_accuracy: 0.9439\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1189 - accuracy: 0.9516 - val_loss: 0.1891 - val_accuracy: 0.9126\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1222 - accuracy: 0.9531 - val_loss: 0.1344 - val_accuracy: 0.9462\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1259 - accuracy: 0.9512 - val_loss: 0.1459 - val_accuracy: 0.9395\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1285 - accuracy: 0.9470 - val_loss: 0.1411 - val_accuracy: 0.9305\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1228 - accuracy: 0.9542 - val_loss: 0.1201 - val_accuracy: 0.9417\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1189 - accuracy: 0.9489 - val_loss: 0.1080 - val_accuracy: 0.9552\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1264 - accuracy: 0.9463 - val_loss: 0.2687 - val_accuracy: 0.8879\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 15s 183ms/step - loss: 0.1260 - accuracy: 0.9489 - val_loss: 0.1427 - val_accuracy: 0.9372\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1205 - accuracy: 0.9546 - val_loss: 0.1413 - val_accuracy: 0.9439\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1171 - accuracy: 0.9561 - val_loss: 0.1637 - val_accuracy: 0.9215\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1168 - accuracy: 0.9535 - val_loss: 0.3338 - val_accuracy: 0.8700\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1309 - accuracy: 0.9429 - val_loss: 0.1171 - val_accuracy: 0.9462\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.1226 - accuracy: 0.9516 - val_loss: 0.1350 - val_accuracy: 0.9372\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1330 - accuracy: 0.9444 - val_loss: 0.1335 - val_accuracy: 0.9305\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1181 - accuracy: 0.9535 - val_loss: 0.1690 - val_accuracy: 0.9327\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1253 - accuracy: 0.9507 - val_loss: 0.2682 - val_accuracy: 0.8834\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1249 - accuracy: 0.9478 - val_loss: 0.1141 - val_accuracy: 0.9462\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1295 - accuracy: 0.9485 - val_loss: 0.1497 - val_accuracy: 0.9439\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1154 - accuracy: 0.9546 - val_loss: 0.1329 - val_accuracy: 0.9417\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1259 - accuracy: 0.9501 - val_loss: 0.2205 - val_accuracy: 0.9148\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1015 - accuracy: 0.9622 - val_loss: 0.1626 - val_accuracy: 0.9260\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1138 - accuracy: 0.9542 - val_loss: 0.1166 - val_accuracy: 0.9462\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1353 - accuracy: 0.9440 - val_loss: 0.1866 - val_accuracy: 0.9260\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1152 - accuracy: 0.9519 - val_loss: 0.1140 - val_accuracy: 0.9462\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1111 - accuracy: 0.9584 - val_loss: 0.1324 - val_accuracy: 0.9417\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1161 - accuracy: 0.9504 - val_loss: 0.1674 - val_accuracy: 0.9215\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1235 - accuracy: 0.9531 - val_loss: 0.2583 - val_accuracy: 0.8812\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1250 - accuracy: 0.9493 - val_loss: 0.1260 - val_accuracy: 0.9417\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1185 - accuracy: 0.9531 - val_loss: 0.1227 - val_accuracy: 0.9462\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.1262 - accuracy: 0.9478 - val_loss: 0.2355 - val_accuracy: 0.9103\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1251 - accuracy: 0.9523 - val_loss: 0.1060 - val_accuracy: 0.9507\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1251 - accuracy: 0.9531 - val_loss: 0.1241 - val_accuracy: 0.9439\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1389 - accuracy: 0.9485 - val_loss: 0.1583 - val_accuracy: 0.9350\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1175 - accuracy: 0.9504 - val_loss: 0.1047 - val_accuracy: 0.9529\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1065 - accuracy: 0.9569 - val_loss: 0.1066 - val_accuracy: 0.9574\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1087 - accuracy: 0.9586 - val_loss: 0.1148 - val_accuracy: 0.9439\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1287 - accuracy: 0.9504 - val_loss: 0.1602 - val_accuracy: 0.9327\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1065 - accuracy: 0.9580 - val_loss: 0.1030 - val_accuracy: 0.9641\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1095 - accuracy: 0.9569 - val_loss: 0.1189 - val_accuracy: 0.9484\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1147 - accuracy: 0.9569 - val_loss: 0.1511 - val_accuracy: 0.9350\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1102 - accuracy: 0.9576 - val_loss: 0.2339 - val_accuracy: 0.8991\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1118 - accuracy: 0.9576 - val_loss: 0.1358 - val_accuracy: 0.9395\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1133 - accuracy: 0.9531 - val_loss: 0.1481 - val_accuracy: 0.9395\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1069 - accuracy: 0.9614 - val_loss: 0.1713 - val_accuracy: 0.9305\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1359 - accuracy: 0.9470 - val_loss: 0.3451 - val_accuracy: 0.8677\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1089 - accuracy: 0.9599 - val_loss: 0.1844 - val_accuracy: 0.9126\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1109 - accuracy: 0.9576 - val_loss: 0.1253 - val_accuracy: 0.9462\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1192 - accuracy: 0.9550 - val_loss: 0.1058 - val_accuracy: 0.9507\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1275 - accuracy: 0.9470 - val_loss: 0.1597 - val_accuracy: 0.9327\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1105 - accuracy: 0.9504 - val_loss: 0.0967 - val_accuracy: 0.9529\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1098 - accuracy: 0.9580 - val_loss: 0.2126 - val_accuracy: 0.8991\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1015 - accuracy: 0.9618 - val_loss: 0.1225 - val_accuracy: 0.9507\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1028 - accuracy: 0.9603 - val_loss: 0.1627 - val_accuracy: 0.9283\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1028 - accuracy: 0.9610 - val_loss: 0.1001 - val_accuracy: 0.9529\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1071 - accuracy: 0.9591 - val_loss: 0.1381 - val_accuracy: 0.9439\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1040 - accuracy: 0.9599 - val_loss: 0.1762 - val_accuracy: 0.9305\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1126 - accuracy: 0.9554 - val_loss: 0.1967 - val_accuracy: 0.9170\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1177 - accuracy: 0.9485 - val_loss: 0.1143 - val_accuracy: 0.9529\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1084 - accuracy: 0.9565 - val_loss: 0.1038 - val_accuracy: 0.9507\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1155 - accuracy: 0.9531 - val_loss: 0.1115 - val_accuracy: 0.9529\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1187 - accuracy: 0.9535 - val_loss: 0.2635 - val_accuracy: 0.8924\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1175 - accuracy: 0.9501 - val_loss: 0.1439 - val_accuracy: 0.9372\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1021 - accuracy: 0.9618 - val_loss: 0.2063 - val_accuracy: 0.9081\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0984 - accuracy: 0.9607 - val_loss: 0.3048 - val_accuracy: 0.8744\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1048 - accuracy: 0.9588 - val_loss: 0.1806 - val_accuracy: 0.9260\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1108 - accuracy: 0.9599 - val_loss: 0.1467 - val_accuracy: 0.9372\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1136 - accuracy: 0.9508 - val_loss: 0.1803 - val_accuracy: 0.9260\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1214 - accuracy: 0.9504 - val_loss: 0.2446 - val_accuracy: 0.8924\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1023 - accuracy: 0.9622 - val_loss: 0.1275 - val_accuracy: 0.9484\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0985 - accuracy: 0.9625 - val_loss: 0.1218 - val_accuracy: 0.9507\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0976 - accuracy: 0.9603 - val_loss: 0.1635 - val_accuracy: 0.9283\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1044 - accuracy: 0.9595 - val_loss: 0.1106 - val_accuracy: 0.9529\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1058 - accuracy: 0.9565 - val_loss: 0.2208 - val_accuracy: 0.9036\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.1087 - accuracy: 0.9588 - val_loss: 0.2152 - val_accuracy: 0.9193\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1120 - accuracy: 0.9554 - val_loss: 0.2338 - val_accuracy: 0.8991\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0970 - accuracy: 0.9637 - val_loss: 0.2783 - val_accuracy: 0.8834\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1308 - accuracy: 0.9432 - val_loss: 0.1388 - val_accuracy: 0.9439\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0974 - accuracy: 0.9627 - val_loss: 0.1310 - val_accuracy: 0.9439\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1057 - accuracy: 0.9561 - val_loss: 0.1452 - val_accuracy: 0.9372\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0995 - accuracy: 0.9595 - val_loss: 0.1437 - val_accuracy: 0.9395\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0981 - accuracy: 0.9633 - val_loss: 0.1466 - val_accuracy: 0.9417\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0950 - accuracy: 0.9652 - val_loss: 0.0981 - val_accuracy: 0.9552\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0973 - accuracy: 0.9595 - val_loss: 0.1004 - val_accuracy: 0.9596\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0941 - accuracy: 0.9637 - val_loss: 0.1310 - val_accuracy: 0.9439\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0914 - accuracy: 0.9663 - val_loss: 0.1491 - val_accuracy: 0.9372\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1006 - accuracy: 0.9588 - val_loss: 0.1259 - val_accuracy: 0.9462\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0917 - accuracy: 0.9652 - val_loss: 0.0912 - val_accuracy: 0.9596\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1028 - accuracy: 0.9588 - val_loss: 0.2031 - val_accuracy: 0.9238\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1032 - accuracy: 0.9603 - val_loss: 0.2366 - val_accuracy: 0.9013\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0925 - accuracy: 0.9614 - val_loss: 0.1346 - val_accuracy: 0.9417\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0993 - accuracy: 0.9576 - val_loss: 0.1188 - val_accuracy: 0.9484\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0906 - accuracy: 0.9663 - val_loss: 0.1099 - val_accuracy: 0.9574\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0913 - accuracy: 0.9633 - val_loss: 0.2916 - val_accuracy: 0.8879\n",
      "Found 3121 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:34: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred= model_test.predict_generator(test_set, len(image_df) // 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 0.27083566784858704; accuracy of 87.99249529838562%\n",
      "Found 2675 validated image filenames belonging to 2 classes.\n",
      "Found 446 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_test.fit_generator( training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0982 - accuracy: 0.9618 - val_loss: 0.2262 - val_accuracy: 0.8991\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0989 - accuracy: 0.9595 - val_loss: 0.1160 - val_accuracy: 0.9552\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1090 - accuracy: 0.9546 - val_loss: 0.2800 - val_accuracy: 0.8677\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1060 - accuracy: 0.9550 - val_loss: 0.1535 - val_accuracy: 0.9417\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0978 - accuracy: 0.9603 - val_loss: 0.1989 - val_accuracy: 0.9103\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1067 - accuracy: 0.9523 - val_loss: 0.1404 - val_accuracy: 0.9507\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1087 - accuracy: 0.9523 - val_loss: 0.1291 - val_accuracy: 0.9417\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1129 - accuracy: 0.9531 - val_loss: 0.1905 - val_accuracy: 0.9126\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1002 - accuracy: 0.9561 - val_loss: 0.1371 - val_accuracy: 0.9395\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0997 - accuracy: 0.9618 - val_loss: 0.0981 - val_accuracy: 0.9686\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0996 - accuracy: 0.9588 - val_loss: 0.1038 - val_accuracy: 0.9596\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1094 - accuracy: 0.9546 - val_loss: 0.1373 - val_accuracy: 0.9350\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0975 - accuracy: 0.9599 - val_loss: 0.2469 - val_accuracy: 0.8789\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1010 - accuracy: 0.9637 - val_loss: 0.1295 - val_accuracy: 0.9552\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1014 - accuracy: 0.9580 - val_loss: 0.1089 - val_accuracy: 0.9596\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0901 - accuracy: 0.9663 - val_loss: 0.2410 - val_accuracy: 0.8946\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1181 - accuracy: 0.9512 - val_loss: 0.2766 - val_accuracy: 0.8767\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 15s 186ms/step - loss: 0.0990 - accuracy: 0.9603 - val_loss: 0.1965 - val_accuracy: 0.9058\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1183 - accuracy: 0.9538 - val_loss: 0.3095 - val_accuracy: 0.8722\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1147 - accuracy: 0.9497 - val_loss: 0.1139 - val_accuracy: 0.9574\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0923 - accuracy: 0.9663 - val_loss: 0.2122 - val_accuracy: 0.9081\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0926 - accuracy: 0.9625 - val_loss: 0.1215 - val_accuracy: 0.9552\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0992 - accuracy: 0.9572 - val_loss: 0.1303 - val_accuracy: 0.9439\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0923 - accuracy: 0.9659 - val_loss: 0.1688 - val_accuracy: 0.9305\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0950 - accuracy: 0.9588 - val_loss: 0.2082 - val_accuracy: 0.9013\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0918 - accuracy: 0.9637 - val_loss: 0.1174 - val_accuracy: 0.9462\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1133 - accuracy: 0.9523 - val_loss: 0.1495 - val_accuracy: 0.9305\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0928 - accuracy: 0.9633 - val_loss: 0.1399 - val_accuracy: 0.9439\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0810 - accuracy: 0.9678 - val_loss: 0.3577 - val_accuracy: 0.8565\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0961 - accuracy: 0.9561 - val_loss: 0.1463 - val_accuracy: 0.9395\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1118 - accuracy: 0.9501 - val_loss: 0.1094 - val_accuracy: 0.9574\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1176 - accuracy: 0.9508 - val_loss: 0.1830 - val_accuracy: 0.9193\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1020 - accuracy: 0.9618 - val_loss: 0.1904 - val_accuracy: 0.9148\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0853 - accuracy: 0.9652 - val_loss: 0.1356 - val_accuracy: 0.9462\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0911 - accuracy: 0.9652 - val_loss: 0.1428 - val_accuracy: 0.9484\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0978 - accuracy: 0.9618 - val_loss: 0.2123 - val_accuracy: 0.8969\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0947 - accuracy: 0.9612 - val_loss: 0.0874 - val_accuracy: 0.9641\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0853 - accuracy: 0.9675 - val_loss: 0.1224 - val_accuracy: 0.9552\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0869 - accuracy: 0.9629 - val_loss: 0.1113 - val_accuracy: 0.9619\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.0955 - accuracy: 0.9580 - val_loss: 0.1439 - val_accuracy: 0.9260\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.0960 - accuracy: 0.9625 - val_loss: 0.2790 - val_accuracy: 0.8722\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 15s 183ms/step - loss: 0.0855 - accuracy: 0.9648 - val_loss: 0.1175 - val_accuracy: 0.9619\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0821 - accuracy: 0.9656 - val_loss: 0.1178 - val_accuracy: 0.9596\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0856 - accuracy: 0.9659 - val_loss: 0.2269 - val_accuracy: 0.8946\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0846 - accuracy: 0.9675 - val_loss: 0.2397 - val_accuracy: 0.8879\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1053 - accuracy: 0.9561 - val_loss: 0.2782 - val_accuracy: 0.8722\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0947 - accuracy: 0.9663 - val_loss: 0.1165 - val_accuracy: 0.9552\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0906 - accuracy: 0.9644 - val_loss: 0.1577 - val_accuracy: 0.9193\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.0888 - accuracy: 0.9663 - val_loss: 0.1185 - val_accuracy: 0.9507\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0887 - accuracy: 0.9618 - val_loss: 0.1645 - val_accuracy: 0.9148\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0962 - accuracy: 0.9595 - val_loss: 0.2865 - val_accuracy: 0.8700\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0832 - accuracy: 0.9671 - val_loss: 0.2473 - val_accuracy: 0.8834\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0792 - accuracy: 0.9671 - val_loss: 0.2009 - val_accuracy: 0.9103\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0780 - accuracy: 0.9709 - val_loss: 0.1538 - val_accuracy: 0.9238\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0848 - accuracy: 0.9667 - val_loss: 0.2041 - val_accuracy: 0.9036\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0936 - accuracy: 0.9607 - val_loss: 0.3063 - val_accuracy: 0.8722\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0961 - accuracy: 0.9607 - val_loss: 0.2773 - val_accuracy: 0.8744\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1042 - accuracy: 0.9572 - val_loss: 0.1564 - val_accuracy: 0.9283\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.0940 - accuracy: 0.9625 - val_loss: 0.2360 - val_accuracy: 0.8767\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0846 - accuracy: 0.9663 - val_loss: 0.1377 - val_accuracy: 0.9372\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0814 - accuracy: 0.9682 - val_loss: 0.1813 - val_accuracy: 0.9058\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1026 - accuracy: 0.9550 - val_loss: 0.1616 - val_accuracy: 0.9238\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0818 - accuracy: 0.9716 - val_loss: 0.2648 - val_accuracy: 0.8767\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0802 - accuracy: 0.9667 - val_loss: 0.1159 - val_accuracy: 0.9574\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0955 - accuracy: 0.9633 - val_loss: 0.1622 - val_accuracy: 0.9238\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0977 - accuracy: 0.9565 - val_loss: 0.1655 - val_accuracy: 0.9126\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0913 - accuracy: 0.9641 - val_loss: 0.2814 - val_accuracy: 0.8767\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0861 - accuracy: 0.9705 - val_loss: 0.1299 - val_accuracy: 0.9395\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0781 - accuracy: 0.9686 - val_loss: 0.2665 - val_accuracy: 0.8812\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0827 - accuracy: 0.9690 - val_loss: 0.1835 - val_accuracy: 0.9126\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0856 - accuracy: 0.9656 - val_loss: 0.1600 - val_accuracy: 0.9081\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0887 - accuracy: 0.9641 - val_loss: 0.1052 - val_accuracy: 0.9686\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0903 - accuracy: 0.9607 - val_loss: 0.4817 - val_accuracy: 0.8184\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1068 - accuracy: 0.9538 - val_loss: 0.2105 - val_accuracy: 0.8991\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0957 - accuracy: 0.9588 - val_loss: 0.1707 - val_accuracy: 0.9126\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0878 - accuracy: 0.9667 - val_loss: 0.2327 - val_accuracy: 0.9058\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0808 - accuracy: 0.9656 - val_loss: 0.3546 - val_accuracy: 0.8565\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1153 - accuracy: 0.9508 - val_loss: 0.1582 - val_accuracy: 0.9417\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0816 - accuracy: 0.9667 - val_loss: 0.2004 - val_accuracy: 0.8991\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0901 - accuracy: 0.9641 - val_loss: 0.5228 - val_accuracy: 0.8161\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0795 - accuracy: 0.9694 - val_loss: 0.1917 - val_accuracy: 0.9103\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0779 - accuracy: 0.9699 - val_loss: 0.1029 - val_accuracy: 0.9552\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1059 - accuracy: 0.9508 - val_loss: 0.1984 - val_accuracy: 0.9058\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0825 - accuracy: 0.9644 - val_loss: 0.1603 - val_accuracy: 0.9238\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0725 - accuracy: 0.9690 - val_loss: 0.1639 - val_accuracy: 0.9193\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0921 - accuracy: 0.9614 - val_loss: 0.5985 - val_accuracy: 0.8049\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0847 - accuracy: 0.9641 - val_loss: 0.3175 - val_accuracy: 0.8587\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0861 - accuracy: 0.9641 - val_loss: 0.1411 - val_accuracy: 0.9305\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0852 - accuracy: 0.9656 - val_loss: 0.3073 - val_accuracy: 0.8722\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0774 - accuracy: 0.9686 - val_loss: 0.1018 - val_accuracy: 0.9664\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0856 - accuracy: 0.9637 - val_loss: 0.2496 - val_accuracy: 0.8812\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0884 - accuracy: 0.9641 - val_loss: 0.2008 - val_accuracy: 0.9036\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 16s 187ms/step - loss: 0.0827 - accuracy: 0.9659 - val_loss: 0.2037 - val_accuracy: 0.9013\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0905 - accuracy: 0.9641 - val_loss: 0.0776 - val_accuracy: 0.9686\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 16s 195ms/step - loss: 0.0900 - accuracy: 0.9625 - val_loss: 0.1876 - val_accuracy: 0.9036\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 15s 185ms/step - loss: 0.0817 - accuracy: 0.9675 - val_loss: 0.3101 - val_accuracy: 0.8700\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.0722 - accuracy: 0.9747 - val_loss: 0.2631 - val_accuracy: 0.8991\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0839 - accuracy: 0.9675 - val_loss: 0.1154 - val_accuracy: 0.9462\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0832 - accuracy: 0.9675 - val_loss: 0.1442 - val_accuracy: 0.9327\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0774 - accuracy: 0.9686 - val_loss: 0.1537 - val_accuracy: 0.9215\n",
      "Found 3121 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:34: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred= model_test.predict_generator(test_set, len(image_df) // 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 0.14894340932369232; accuracy of 93.05816292762756%\n",
      "Found 2675 validated image filenames belonging to 2 classes.\n",
      "Found 446 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_test.fit_generator( training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0845 - accuracy: 0.9644 - val_loss: 0.2264 - val_accuracy: 0.9148\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0924 - accuracy: 0.9633 - val_loss: 0.2253 - val_accuracy: 0.9170\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.1128 - accuracy: 0.9554 - val_loss: 0.2330 - val_accuracy: 0.9103\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 15s 183ms/step - loss: 0.0821 - accuracy: 0.9652 - val_loss: 0.1952 - val_accuracy: 0.9260\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0929 - accuracy: 0.9637 - val_loss: 0.1780 - val_accuracy: 0.9283\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0945 - accuracy: 0.9622 - val_loss: 0.1407 - val_accuracy: 0.9395\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0855 - accuracy: 0.9682 - val_loss: 0.2533 - val_accuracy: 0.9036\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0754 - accuracy: 0.9697 - val_loss: 0.2305 - val_accuracy: 0.9103\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0847 - accuracy: 0.9678 - val_loss: 0.0797 - val_accuracy: 0.9641\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1041 - accuracy: 0.9542 - val_loss: 0.0669 - val_accuracy: 0.9731\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0822 - accuracy: 0.9690 - val_loss: 0.1354 - val_accuracy: 0.9484\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0859 - accuracy: 0.9682 - val_loss: 0.1619 - val_accuracy: 0.9417\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0851 - accuracy: 0.9690 - val_loss: 0.1587 - val_accuracy: 0.9305\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0846 - accuracy: 0.9671 - val_loss: 0.2520 - val_accuracy: 0.8991\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0772 - accuracy: 0.9712 - val_loss: 0.0987 - val_accuracy: 0.9552\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0864 - accuracy: 0.9652 - val_loss: 0.2314 - val_accuracy: 0.9103\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0768 - accuracy: 0.9686 - val_loss: 0.1473 - val_accuracy: 0.9395\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0907 - accuracy: 0.9656 - val_loss: 0.2381 - val_accuracy: 0.9170\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0831 - accuracy: 0.9675 - val_loss: 0.0719 - val_accuracy: 0.9709\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1095 - accuracy: 0.9538 - val_loss: 0.0677 - val_accuracy: 0.9731\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0891 - accuracy: 0.9618 - val_loss: 0.2284 - val_accuracy: 0.8991\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0819 - accuracy: 0.9652 - val_loss: 0.2304 - val_accuracy: 0.9036\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0793 - accuracy: 0.9716 - val_loss: 0.1060 - val_accuracy: 0.9529\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0816 - accuracy: 0.9678 - val_loss: 0.2377 - val_accuracy: 0.9126\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0838 - accuracy: 0.9656 - val_loss: 0.2219 - val_accuracy: 0.9103\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0930 - accuracy: 0.9625 - val_loss: 0.1018 - val_accuracy: 0.9552\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0900 - accuracy: 0.9625 - val_loss: 0.2407 - val_accuracy: 0.9013\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0765 - accuracy: 0.9731 - val_loss: 0.1786 - val_accuracy: 0.9350\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0797 - accuracy: 0.9663 - val_loss: 0.3156 - val_accuracy: 0.8812\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0768 - accuracy: 0.9686 - val_loss: 0.1977 - val_accuracy: 0.9148\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0731 - accuracy: 0.9709 - val_loss: 0.0625 - val_accuracy: 0.9776\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0923 - accuracy: 0.9618 - val_loss: 0.0896 - val_accuracy: 0.9596\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.1022 - accuracy: 0.9569 - val_loss: 0.1426 - val_accuracy: 0.9484\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0860 - accuracy: 0.9637 - val_loss: 0.2375 - val_accuracy: 0.9058\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0763 - accuracy: 0.9663 - val_loss: 0.1139 - val_accuracy: 0.9529\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0870 - accuracy: 0.9648 - val_loss: 0.2518 - val_accuracy: 0.8991\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0750 - accuracy: 0.9697 - val_loss: 0.1917 - val_accuracy: 0.9238\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0817 - accuracy: 0.9667 - val_loss: 0.2534 - val_accuracy: 0.8991\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0846 - accuracy: 0.9656 - val_loss: 0.2175 - val_accuracy: 0.9013\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0802 - accuracy: 0.9652 - val_loss: 0.0908 - val_accuracy: 0.9552\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0722 - accuracy: 0.9750 - val_loss: 0.0901 - val_accuracy: 0.9686\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0866 - accuracy: 0.9644 - val_loss: 0.1826 - val_accuracy: 0.9283\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0723 - accuracy: 0.9735 - val_loss: 0.2037 - val_accuracy: 0.9193\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0716 - accuracy: 0.9720 - val_loss: 0.0932 - val_accuracy: 0.9641\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0693 - accuracy: 0.9720 - val_loss: 0.0679 - val_accuracy: 0.9731\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0869 - accuracy: 0.9663 - val_loss: 0.2198 - val_accuracy: 0.9170\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0805 - accuracy: 0.9690 - val_loss: 0.2498 - val_accuracy: 0.8969\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.0712 - accuracy: 0.9765 - val_loss: 0.2081 - val_accuracy: 0.9260\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0709 - accuracy: 0.9705 - val_loss: 0.1246 - val_accuracy: 0.9462\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0874 - accuracy: 0.9652 - val_loss: 0.1783 - val_accuracy: 0.9305\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0789 - accuracy: 0.9659 - val_loss: 0.2341 - val_accuracy: 0.9148\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0771 - accuracy: 0.9686 - val_loss: 0.1443 - val_accuracy: 0.9327\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0756 - accuracy: 0.9716 - val_loss: 0.1373 - val_accuracy: 0.9395\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0771 - accuracy: 0.9675 - val_loss: 0.2101 - val_accuracy: 0.9238\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0751 - accuracy: 0.9709 - val_loss: 0.1614 - val_accuracy: 0.9350\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0782 - accuracy: 0.9684 - val_loss: 0.1057 - val_accuracy: 0.9574\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0879 - accuracy: 0.9637 - val_loss: 0.1476 - val_accuracy: 0.9484\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0716 - accuracy: 0.9712 - val_loss: 0.2018 - val_accuracy: 0.9327\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0646 - accuracy: 0.9747 - val_loss: 0.1305 - val_accuracy: 0.9439\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0738 - accuracy: 0.9663 - val_loss: 0.0948 - val_accuracy: 0.9641\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.0679 - accuracy: 0.9743 - val_loss: 0.1570 - val_accuracy: 0.9417\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 15s 181ms/step - loss: 0.0825 - accuracy: 0.9644 - val_loss: 0.1925 - val_accuracy: 0.9215\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0727 - accuracy: 0.9735 - val_loss: 0.1522 - val_accuracy: 0.9327\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0703 - accuracy: 0.9716 - val_loss: 0.1720 - val_accuracy: 0.9327\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0767 - accuracy: 0.9705 - val_loss: 0.2013 - val_accuracy: 0.9260\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0720 - accuracy: 0.9720 - val_loss: 0.2469 - val_accuracy: 0.9170\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0705 - accuracy: 0.9709 - val_loss: 0.2563 - val_accuracy: 0.8991\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0681 - accuracy: 0.9731 - val_loss: 0.0910 - val_accuracy: 0.9619\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0693 - accuracy: 0.9716 - val_loss: 0.2745 - val_accuracy: 0.8924\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.1085 - accuracy: 0.9546 - val_loss: 0.0427 - val_accuracy: 0.9821\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0895 - accuracy: 0.9614 - val_loss: 0.1189 - val_accuracy: 0.9507\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0644 - accuracy: 0.9765 - val_loss: 0.1130 - val_accuracy: 0.9574\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0815 - accuracy: 0.9644 - val_loss: 0.1939 - val_accuracy: 0.9260\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 15s 185ms/step - loss: 0.0667 - accuracy: 0.9747 - val_loss: 0.1557 - val_accuracy: 0.9327\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0699 - accuracy: 0.9709 - val_loss: 0.3515 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0865 - accuracy: 0.9644 - val_loss: 0.1161 - val_accuracy: 0.9507\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0597 - accuracy: 0.9773 - val_loss: 0.3423 - val_accuracy: 0.8744\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0680 - accuracy: 0.9694 - val_loss: 0.0969 - val_accuracy: 0.9619\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0682 - accuracy: 0.9743 - val_loss: 0.1879 - val_accuracy: 0.9260\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0889 - accuracy: 0.9652 - val_loss: 0.0660 - val_accuracy: 0.9709\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0809 - accuracy: 0.9659 - val_loss: 0.4360 - val_accuracy: 0.8610\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0831 - accuracy: 0.9671 - val_loss: 0.0603 - val_accuracy: 0.9753\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0935 - accuracy: 0.9614 - val_loss: 0.1487 - val_accuracy: 0.9395\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0607 - accuracy: 0.9762 - val_loss: 0.2294 - val_accuracy: 0.9103\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0727 - accuracy: 0.9724 - val_loss: 0.2288 - val_accuracy: 0.9103\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0662 - accuracy: 0.9720 - val_loss: 0.4132 - val_accuracy: 0.8520\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0705 - accuracy: 0.9716 - val_loss: 0.2260 - val_accuracy: 0.9081\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0799 - accuracy: 0.9667 - val_loss: 0.1770 - val_accuracy: 0.9260\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0638 - accuracy: 0.9750 - val_loss: 0.2316 - val_accuracy: 0.9058\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0835 - accuracy: 0.9656 - val_loss: 0.1257 - val_accuracy: 0.9484\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0658 - accuracy: 0.9758 - val_loss: 0.0987 - val_accuracy: 0.9596\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0625 - accuracy: 0.9777 - val_loss: 0.2456 - val_accuracy: 0.9081\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0669 - accuracy: 0.9724 - val_loss: 0.1391 - val_accuracy: 0.9417\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0724 - accuracy: 0.9716 - val_loss: 0.1805 - val_accuracy: 0.9260\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0746 - accuracy: 0.9712 - val_loss: 0.3156 - val_accuracy: 0.8879\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0688 - accuracy: 0.9739 - val_loss: 0.1543 - val_accuracy: 0.9350\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0640 - accuracy: 0.9769 - val_loss: 0.2649 - val_accuracy: 0.9058\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0692 - accuracy: 0.9728 - val_loss: 0.1162 - val_accuracy: 0.9484\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0535 - accuracy: 0.9781 - val_loss: 0.2400 - val_accuracy: 0.9170\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0643 - accuracy: 0.9735 - val_loss: 0.1971 - val_accuracy: 0.9193\n",
      "Found 3121 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:34: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred= model_test.predict_generator(test_set, len(image_df) // 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 0.22076085209846497; accuracy of 91.36960506439209%\n",
      "Found 2675 validated image filenames belonging to 2 classes.\n",
      "Found 446 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_test.fit_generator( training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0739 - accuracy: 0.9709 - val_loss: 0.2122 - val_accuracy: 0.9260\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0645 - accuracy: 0.9720 - val_loss: 0.2348 - val_accuracy: 0.9170\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0581 - accuracy: 0.9762 - val_loss: 0.5531 - val_accuracy: 0.8184\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0651 - accuracy: 0.9739 - val_loss: 0.1918 - val_accuracy: 0.9305\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0580 - accuracy: 0.9784 - val_loss: 0.3325 - val_accuracy: 0.8744\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0638 - accuracy: 0.9731 - val_loss: 0.3571 - val_accuracy: 0.8789\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0640 - accuracy: 0.9739 - val_loss: 0.2102 - val_accuracy: 0.9238\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0774 - accuracy: 0.9694 - val_loss: 0.6064 - val_accuracy: 0.8184\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0705 - accuracy: 0.9712 - val_loss: 0.2789 - val_accuracy: 0.8901\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 16s 187ms/step - loss: 0.0628 - accuracy: 0.9743 - val_loss: 0.3361 - val_accuracy: 0.8700\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 16s 188ms/step - loss: 0.0653 - accuracy: 0.9754 - val_loss: 0.2932 - val_accuracy: 0.8879\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0528 - accuracy: 0.9796 - val_loss: 0.1591 - val_accuracy: 0.9395\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0592 - accuracy: 0.9769 - val_loss: 0.3074 - val_accuracy: 0.8879\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 17s 198ms/step - loss: 0.0684 - accuracy: 0.9710 - val_loss: 0.5023 - val_accuracy: 0.8475\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0558 - accuracy: 0.9773 - val_loss: 0.2523 - val_accuracy: 0.9058\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0690 - accuracy: 0.9728 - val_loss: 0.2232 - val_accuracy: 0.9193\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 14s 174ms/step - loss: 0.0823 - accuracy: 0.9686 - val_loss: 0.1754 - val_accuracy: 0.9305\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0554 - accuracy: 0.9799 - val_loss: 0.4781 - val_accuracy: 0.8430\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0558 - accuracy: 0.9811 - val_loss: 0.2318 - val_accuracy: 0.9193\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0635 - accuracy: 0.9754 - val_loss: 0.3298 - val_accuracy: 0.8789\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 14s 174ms/step - loss: 0.0558 - accuracy: 0.9769 - val_loss: 0.2136 - val_accuracy: 0.9238\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 14s 173ms/step - loss: 0.0633 - accuracy: 0.9765 - val_loss: 0.1268 - val_accuracy: 0.9529\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0636 - accuracy: 0.9743 - val_loss: 0.2574 - val_accuracy: 0.9081\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0560 - accuracy: 0.9777 - val_loss: 0.3163 - val_accuracy: 0.8879\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 14s 174ms/step - loss: 0.0623 - accuracy: 0.9750 - val_loss: 0.1688 - val_accuracy: 0.9350\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 14s 173ms/step - loss: 0.0549 - accuracy: 0.9788 - val_loss: 0.4743 - val_accuracy: 0.8498\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 14s 174ms/step - loss: 0.0603 - accuracy: 0.9765 - val_loss: 0.2744 - val_accuracy: 0.9036\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0612 - accuracy: 0.9750 - val_loss: 0.1778 - val_accuracy: 0.9350\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0806 - accuracy: 0.9652 - val_loss: 0.1877 - val_accuracy: 0.9305\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 16s 189ms/step - loss: 0.0574 - accuracy: 0.9807 - val_loss: 0.1828 - val_accuracy: 0.9350\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 16s 191ms/step - loss: 0.0534 - accuracy: 0.9788 - val_loss: 0.5949 - val_accuracy: 0.8161\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.1014 - accuracy: 0.9603 - val_loss: 0.2062 - val_accuracy: 0.9283\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 16s 197ms/step - loss: 0.0697 - accuracy: 0.9709 - val_loss: 0.2291 - val_accuracy: 0.9103\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 17s 199ms/step - loss: 0.0479 - accuracy: 0.9807 - val_loss: 0.2674 - val_accuracy: 0.9036\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 17s 208ms/step - loss: 0.0583 - accuracy: 0.9750 - val_loss: 0.1038 - val_accuracy: 0.9686\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0628 - accuracy: 0.9769 - val_loss: 0.3547 - val_accuracy: 0.8789\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0525 - accuracy: 0.9788 - val_loss: 0.2839 - val_accuracy: 0.8924\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0583 - accuracy: 0.9762 - val_loss: 0.4328 - val_accuracy: 0.8475\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0518 - accuracy: 0.9784 - val_loss: 0.2993 - val_accuracy: 0.9103\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0617 - accuracy: 0.9769 - val_loss: 0.1968 - val_accuracy: 0.9327\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0626 - accuracy: 0.9728 - val_loss: 0.4032 - val_accuracy: 0.8610\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0566 - accuracy: 0.9750 - val_loss: 0.5669 - val_accuracy: 0.8229\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.1029 - accuracy: 0.9591 - val_loss: 0.1516 - val_accuracy: 0.9462\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0623 - accuracy: 0.9758 - val_loss: 0.1584 - val_accuracy: 0.9417\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0528 - accuracy: 0.9803 - val_loss: 0.2197 - val_accuracy: 0.9238\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0552 - accuracy: 0.9777 - val_loss: 0.1270 - val_accuracy: 0.9529\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0590 - accuracy: 0.9750 - val_loss: 0.2934 - val_accuracy: 0.8789\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0580 - accuracy: 0.9777 - val_loss: 0.3699 - val_accuracy: 0.8789\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0548 - accuracy: 0.9781 - val_loss: 0.3268 - val_accuracy: 0.8834\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0483 - accuracy: 0.9856 - val_loss: 0.3612 - val_accuracy: 0.8767\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0488 - accuracy: 0.9822 - val_loss: 0.2714 - val_accuracy: 0.9081\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0728 - accuracy: 0.9694 - val_loss: 0.1673 - val_accuracy: 0.9395\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0492 - accuracy: 0.9811 - val_loss: 0.3919 - val_accuracy: 0.8587\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0504 - accuracy: 0.9822 - val_loss: 0.1852 - val_accuracy: 0.9417\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0569 - accuracy: 0.9781 - val_loss: 0.2306 - val_accuracy: 0.9260\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0582 - accuracy: 0.9750 - val_loss: 0.2963 - val_accuracy: 0.8946\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0485 - accuracy: 0.9803 - val_loss: 0.1275 - val_accuracy: 0.9507\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0791 - accuracy: 0.9663 - val_loss: 0.3309 - val_accuracy: 0.8924\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0759 - accuracy: 0.9686 - val_loss: 0.2813 - val_accuracy: 0.9058\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0560 - accuracy: 0.9792 - val_loss: 0.5228 - val_accuracy: 0.8363\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0608 - accuracy: 0.9769 - val_loss: 0.2994 - val_accuracy: 0.8924\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0575 - accuracy: 0.9796 - val_loss: 0.3386 - val_accuracy: 0.8789\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0518 - accuracy: 0.9811 - val_loss: 0.2931 - val_accuracy: 0.9013\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0623 - accuracy: 0.9750 - val_loss: 0.3577 - val_accuracy: 0.8722\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0658 - accuracy: 0.9720 - val_loss: 0.3970 - val_accuracy: 0.8700\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0485 - accuracy: 0.9834 - val_loss: 0.4289 - val_accuracy: 0.8543\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0516 - accuracy: 0.9799 - val_loss: 0.2195 - val_accuracy: 0.9170\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0512 - accuracy: 0.9818 - val_loss: 0.3147 - val_accuracy: 0.8857\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0641 - accuracy: 0.9743 - val_loss: 0.3911 - val_accuracy: 0.8722\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0563 - accuracy: 0.9777 - val_loss: 0.1951 - val_accuracy: 0.9350\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0570 - accuracy: 0.9792 - val_loss: 0.1749 - val_accuracy: 0.9305\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0553 - accuracy: 0.9792 - val_loss: 0.1357 - val_accuracy: 0.9529\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 15s 183ms/step - loss: 0.0554 - accuracy: 0.9777 - val_loss: 0.1391 - val_accuracy: 0.9439\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 15s 179ms/step - loss: 0.0640 - accuracy: 0.9716 - val_loss: 0.6941 - val_accuracy: 0.7870\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0476 - accuracy: 0.9826 - val_loss: 0.3135 - val_accuracy: 0.8767\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0476 - accuracy: 0.9841 - val_loss: 0.4230 - val_accuracy: 0.8610\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0521 - accuracy: 0.9792 - val_loss: 0.1984 - val_accuracy: 0.9327\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0542 - accuracy: 0.9773 - val_loss: 0.3758 - val_accuracy: 0.8677\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 0.3254 - val_accuracy: 0.8991\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0592 - accuracy: 0.9754 - val_loss: 0.1421 - val_accuracy: 0.9507\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0522 - accuracy: 0.9807 - val_loss: 0.5542 - val_accuracy: 0.8318\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 15s 180ms/step - loss: 0.0696 - accuracy: 0.9716 - val_loss: 0.6278 - val_accuracy: 0.7982\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0518 - accuracy: 0.9803 - val_loss: 0.2952 - val_accuracy: 0.8991\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0465 - accuracy: 0.9822 - val_loss: 0.2556 - val_accuracy: 0.9081\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0532 - accuracy: 0.9799 - val_loss: 0.3184 - val_accuracy: 0.8901\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0681 - accuracy: 0.9743 - val_loss: 0.2141 - val_accuracy: 0.9305\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0549 - accuracy: 0.9784 - val_loss: 0.3281 - val_accuracy: 0.8991\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 14s 174ms/step - loss: 0.0586 - accuracy: 0.9769 - val_loss: 0.5895 - val_accuracy: 0.8318\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0559 - accuracy: 0.9788 - val_loss: 0.1668 - val_accuracy: 0.9372\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0529 - accuracy: 0.9788 - val_loss: 0.2107 - val_accuracy: 0.9238\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0537 - accuracy: 0.9788 - val_loss: 0.1657 - val_accuracy: 0.9439\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 0.3736 - val_accuracy: 0.8767\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.3858 - val_accuracy: 0.8632\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0612 - accuracy: 0.9743 - val_loss: 0.4720 - val_accuracy: 0.8475\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0586 - accuracy: 0.9754 - val_loss: 0.5669 - val_accuracy: 0.8206\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0512 - accuracy: 0.9788 - val_loss: 0.2873 - val_accuracy: 0.9103\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0478 - accuracy: 0.9830 - val_loss: 0.3334 - val_accuracy: 0.8857\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0456 - accuracy: 0.9834 - val_loss: 0.4684 - val_accuracy: 0.8543\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0420 - accuracy: 0.9845 - val_loss: 0.5073 - val_accuracy: 0.8363\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0616 - accuracy: 0.9796 - val_loss: 0.2205 - val_accuracy: 0.9238\n",
      "Found 3121 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:34: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred= model_test.predict_generator(test_set, len(image_df) // 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 6: loss of 0.21943311393260956; accuracy of 91.93245768547058%\n",
      "Found 2676 validated image filenames belonging to 2 classes.\n",
      "Found 445 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model_test.fit_generator( training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 181ms/step - loss: 0.0586 - accuracy: 0.9769 - val_loss: 0.0884 - val_accuracy: 0.9618\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0461 - accuracy: 0.9826 - val_loss: 0.0903 - val_accuracy: 0.9618\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0491 - accuracy: 0.9807 - val_loss: 0.1557 - val_accuracy: 0.9438\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0499 - accuracy: 0.9803 - val_loss: 0.1822 - val_accuracy: 0.9281\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0911 - accuracy: 0.9614 - val_loss: 0.3745 - val_accuracy: 0.8562\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0591 - accuracy: 0.9788 - val_loss: 0.2395 - val_accuracy: 0.9056\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0562 - accuracy: 0.9784 - val_loss: 0.0919 - val_accuracy: 0.9596\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 15s 185ms/step - loss: 0.0584 - accuracy: 0.9754 - val_loss: 0.1568 - val_accuracy: 0.9348\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0500 - accuracy: 0.9788 - val_loss: 0.1886 - val_accuracy: 0.9191\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0461 - accuracy: 0.9822 - val_loss: 0.3745 - val_accuracy: 0.8517\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0504 - accuracy: 0.9800 - val_loss: 0.1732 - val_accuracy: 0.9281\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0471 - accuracy: 0.9818 - val_loss: 0.2220 - val_accuracy: 0.9213\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0595 - accuracy: 0.9747 - val_loss: 0.5889 - val_accuracy: 0.8067\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0499 - accuracy: 0.9796 - val_loss: 0.2031 - val_accuracy: 0.9124\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0498 - accuracy: 0.9826 - val_loss: 0.0646 - val_accuracy: 0.9730\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0502 - accuracy: 0.9800 - val_loss: 0.0954 - val_accuracy: 0.9640\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0813 - accuracy: 0.9667 - val_loss: 0.0709 - val_accuracy: 0.9663\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0508 - accuracy: 0.9837 - val_loss: 0.1910 - val_accuracy: 0.9191\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0552 - accuracy: 0.9796 - val_loss: 0.2007 - val_accuracy: 0.9258\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0523 - accuracy: 0.9788 - val_loss: 0.5831 - val_accuracy: 0.7978\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0533 - accuracy: 0.9769 - val_loss: 0.2396 - val_accuracy: 0.8854\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 14s 174ms/step - loss: 0.0493 - accuracy: 0.9818 - val_loss: 0.3195 - val_accuracy: 0.8719\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0475 - accuracy: 0.9822 - val_loss: 0.2829 - val_accuracy: 0.8764\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0602 - accuracy: 0.9758 - val_loss: 0.1328 - val_accuracy: 0.9528\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0485 - accuracy: 0.9811 - val_loss: 0.1848 - val_accuracy: 0.9236\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0460 - accuracy: 0.9834 - val_loss: 0.1098 - val_accuracy: 0.9551\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0482 - accuracy: 0.9796 - val_loss: 0.0734 - val_accuracy: 0.9753\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0490 - accuracy: 0.9822 - val_loss: 0.1755 - val_accuracy: 0.9393\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0600 - accuracy: 0.9769 - val_loss: 0.2075 - val_accuracy: 0.9056\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0461 - accuracy: 0.9800 - val_loss: 0.4968 - val_accuracy: 0.8382\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0450 - accuracy: 0.9818 - val_loss: 0.1710 - val_accuracy: 0.9303\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0425 - accuracy: 0.9849 - val_loss: 0.3120 - val_accuracy: 0.8697\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0436 - accuracy: 0.9841 - val_loss: 0.3763 - val_accuracy: 0.8584\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0535 - accuracy: 0.9777 - val_loss: 0.3031 - val_accuracy: 0.8809\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0608 - accuracy: 0.9800 - val_loss: 0.2183 - val_accuracy: 0.9169\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0548 - accuracy: 0.9796 - val_loss: 0.2173 - val_accuracy: 0.8966\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0531 - accuracy: 0.9792 - val_loss: 0.1421 - val_accuracy: 0.9438\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0645 - accuracy: 0.9762 - val_loss: 0.2396 - val_accuracy: 0.8921\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0470 - accuracy: 0.9811 - val_loss: 0.0591 - val_accuracy: 0.9753\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0537 - accuracy: 0.9769 - val_loss: 0.1669 - val_accuracy: 0.9258\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0499 - accuracy: 0.9834 - val_loss: 0.2340 - val_accuracy: 0.9034\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0451 - accuracy: 0.9837 - val_loss: 0.1120 - val_accuracy: 0.9596\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0571 - accuracy: 0.9777 - val_loss: 0.3099 - val_accuracy: 0.8742\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0583 - accuracy: 0.9781 - val_loss: 0.6789 - val_accuracy: 0.8067\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0539 - accuracy: 0.9807 - val_loss: 0.2713 - val_accuracy: 0.8742\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0459 - accuracy: 0.9815 - val_loss: 0.2320 - val_accuracy: 0.8966\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0482 - accuracy: 0.9818 - val_loss: 0.2409 - val_accuracy: 0.9034\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0437 - accuracy: 0.9860 - val_loss: 0.2289 - val_accuracy: 0.8989\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0444 - accuracy: 0.9845 - val_loss: 0.4926 - val_accuracy: 0.8382\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0478 - accuracy: 0.9841 - val_loss: 0.2114 - val_accuracy: 0.9079\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0499 - accuracy: 0.9826 - val_loss: 0.1427 - val_accuracy: 0.9461\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0465 - accuracy: 0.9822 - val_loss: 0.1949 - val_accuracy: 0.9236\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0449 - accuracy: 0.9807 - val_loss: 0.1422 - val_accuracy: 0.9416\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0558 - accuracy: 0.9754 - val_loss: 0.0705 - val_accuracy: 0.9730\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0478 - accuracy: 0.9803 - val_loss: 0.1017 - val_accuracy: 0.9528\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0513 - accuracy: 0.9777 - val_loss: 0.3502 - val_accuracy: 0.8607\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0563 - accuracy: 0.9792 - val_loss: 0.0924 - val_accuracy: 0.9663\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0404 - accuracy: 0.9837 - val_loss: 0.1587 - val_accuracy: 0.9371\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 14s 174ms/step - loss: 0.0547 - accuracy: 0.9781 - val_loss: 0.1903 - val_accuracy: 0.9258\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.1947 - val_accuracy: 0.9213\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.1774 - val_accuracy: 0.9169\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0465 - accuracy: 0.9803 - val_loss: 0.3481 - val_accuracy: 0.8674\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0504 - accuracy: 0.9792 - val_loss: 0.1182 - val_accuracy: 0.9640\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0407 - accuracy: 0.9856 - val_loss: 0.2799 - val_accuracy: 0.8809\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0528 - accuracy: 0.9784 - val_loss: 0.4230 - val_accuracy: 0.8652\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0496 - accuracy: 0.9826 - val_loss: 0.2828 - val_accuracy: 0.8719\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.1576 - val_accuracy: 0.9281\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0459 - accuracy: 0.9837 - val_loss: 0.2806 - val_accuracy: 0.8921\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0421 - accuracy: 0.9860 - val_loss: 0.0962 - val_accuracy: 0.9618\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0458 - accuracy: 0.9815 - val_loss: 0.2970 - val_accuracy: 0.8652\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0489 - accuracy: 0.9800 - val_loss: 0.3875 - val_accuracy: 0.8494\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0517 - accuracy: 0.9796 - val_loss: 0.3774 - val_accuracy: 0.8472\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0498 - accuracy: 0.9803 - val_loss: 0.3678 - val_accuracy: 0.8607\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0499 - accuracy: 0.9807 - val_loss: 0.0864 - val_accuracy: 0.9596\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0436 - accuracy: 0.9837 - val_loss: 0.2080 - val_accuracy: 0.9146\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0355 - accuracy: 0.9871 - val_loss: 0.3281 - val_accuracy: 0.8674\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 15s 177ms/step - loss: 0.0518 - accuracy: 0.9784 - val_loss: 0.2464 - val_accuracy: 0.8899\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0445 - accuracy: 0.9830 - val_loss: 0.0625 - val_accuracy: 0.9753\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0424 - accuracy: 0.9830 - val_loss: 0.2092 - val_accuracy: 0.9011\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0433 - accuracy: 0.9826 - val_loss: 0.1377 - val_accuracy: 0.9528\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0460 - accuracy: 0.9834 - val_loss: 0.1805 - val_accuracy: 0.9281\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0491 - accuracy: 0.9800 - val_loss: 0.1595 - val_accuracy: 0.9371\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 15s 178ms/step - loss: 0.0431 - accuracy: 0.9822 - val_loss: 0.1419 - val_accuracy: 0.9461\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0446 - accuracy: 0.9849 - val_loss: 0.0978 - val_accuracy: 0.9640\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0402 - accuracy: 0.9845 - val_loss: 0.4752 - val_accuracy: 0.8494\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0481 - accuracy: 0.9811 - val_loss: 0.0985 - val_accuracy: 0.9685\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 15s 174ms/step - loss: 0.0444 - accuracy: 0.9811 - val_loss: 0.1251 - val_accuracy: 0.9506\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0365 - accuracy: 0.9864 - val_loss: 0.2803 - val_accuracy: 0.8764\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0508 - accuracy: 0.9826 - val_loss: 0.3089 - val_accuracy: 0.8787\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0594 - accuracy: 0.9739 - val_loss: 0.1270 - val_accuracy: 0.9573\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0413 - accuracy: 0.9834 - val_loss: 0.2055 - val_accuracy: 0.9079\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0431 - accuracy: 0.9815 - val_loss: 0.1862 - val_accuracy: 0.9191\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0369 - accuracy: 0.9864 - val_loss: 0.2108 - val_accuracy: 0.9124\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0405 - accuracy: 0.9849 - val_loss: 0.3710 - val_accuracy: 0.8427\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0449 - accuracy: 0.9822 - val_loss: 0.1421 - val_accuracy: 0.9461\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0423 - accuracy: 0.9822 - val_loss: 0.3631 - val_accuracy: 0.8652\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0523 - accuracy: 0.9815 - val_loss: 0.1281 - val_accuracy: 0.9483\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0411 - accuracy: 0.9837 - val_loss: 0.1882 - val_accuracy: 0.9213\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 15s 176ms/step - loss: 0.0504 - accuracy: 0.9811 - val_loss: 0.2700 - val_accuracy: 0.8876\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 15s 175ms/step - loss: 0.0386 - accuracy: 0.9841 - val_loss: 0.1110 - val_accuracy: 0.9618\n",
      "Found 3121 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/phpbsbv92qjbjcmfjm3dtyvh0000gn/T/ipykernel_25985/4144958558.py:34: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  pred= model_test.predict_generator(test_set, len(image_df) // 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 7: loss of 0.11481539905071259; accuracy of 94.93433237075806%\n"
     ]
    }
   ],
   "source": [
    "# K-fold Train and test for each split\n",
    "for train_idx, val_idx in list(kfold.split(train_x,train_y)):\n",
    "    x_train_df = image_df.iloc[train_idx]\n",
    "    x_valid_df = image_df.iloc[val_idx]\n",
    "    j+=1\n",
    "\n",
    "\n",
    "    training_set = train_datagen.flow_from_dataframe(dataframe=x_train_df, \n",
    "                                                 x_col=\"Filepath\", y_col=\"Label\",\n",
    "                                                 class_mode=\"binary\",\n",
    "                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=32)\n",
    "    \n",
    "    validation_set = validation_datagen.flow_from_dataframe(dataframe=x_valid_df,\n",
    "                                                 x_col=\"Filepath\", y_col=\"Label\",\n",
    "                                                 class_mode=\"binary\",\n",
    "                                                 target_size=(IMG_SIZE,IMG_SIZE), batch_size=32)\n",
    "    \n",
    "    model_test = get_model()\n",
    "    \n",
    "    \n",
    "    history = model_test.fit_generator( training_set,\n",
    "                                        validation_data=validation_set,\n",
    "                                        epochs = EPOCHS,\n",
    "                                        steps_per_epoch=x_train_df.shape[0] // BATCH_SIZE\n",
    "                                        )\n",
    "    \n",
    "    test_generator = ImageDataGenerator(rescale = 1./255)\n",
    "    \n",
    "    test_set = test_generator.flow_from_dataframe(dataframe=image_df,\n",
    "                                                 x_col=\"Filepath\",y_col=None,\n",
    "                                                 class_mode=None,\n",
    "                                                 target_size=(IMG_SIZE,IMG_SIZE))\n",
    "    \n",
    "    pred= model_test.predict_generator(test_set, len(image_df) // 32)\n",
    "    predicted_class_indices=np.argmax(pred,axis=1)\n",
    "                                       \n",
    "    data_kfold[j] = predicted_class_indices\n",
    "    gc.collect()\n",
    "      # Generate generalization metrics\n",
    "    scores = model_test.evaluate(test_images, verbose = 0)\n",
    "    print(f'Score for fold {j}: {model_test.metrics_names[0]} of {scores[0]}; {model_test.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    models.append(model_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87d9fa82-f87a-4314-972d-22e1b5f779d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.1552063226699829 - Accuracy: 93.24578046798706%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.17134647071361542 - Accuracy: 92.49531030654907%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.27083566784858704 - Accuracy: 87.99249529838562%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.14894340932369232 - Accuracy: 93.05816292762756%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.22076085209846497 - Accuracy: 91.36960506439209%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 6 - Loss: 0.21943311393260956 - Accuracy: 91.93245768547058%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 7 - Loss: 0.11481539905071259 - Accuracy: 94.93433237075806%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 92.14687773159572 (+- 1.9942187411887196)\n",
      "> Loss: 0.1859058908053807\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d73a0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.05490196, 0.05490196, 0.05490196],\n",
       "         [0.03921569, 0.03921569, 0.03921569],\n",
       "         [0.03921569, 0.03921569, 0.03921569]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.01960784, 0.01960784, 0.01960784],\n",
       "         [0.02352941, 0.02352941, 0.02352941],\n",
       "         [0.02352941, 0.02352941, 0.02352941]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       [[[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00392157, 0.00392157, 0.00392157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.00392157, 0.00392157, 0.00392157],\n",
       "         [0.00784314, 0.00784314, 0.00784314],\n",
       "         [0.00784314, 0.00784314, 0.00784314]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec19e8cf-2f65-4a0b-83eb-76e5b3f2268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.65757214e-02],\n",
       "       [9.86977398e-01],\n",
       "       [2.11699793e-04],\n",
       "       [1.24762219e-03],\n",
       "       [9.99999523e-01],\n",
       "       [3.07413144e-03],\n",
       "       [9.99999046e-01],\n",
       "       [1.00716272e-06],\n",
       "       [9.99999881e-01],\n",
       "       [9.33115244e-01],\n",
       "       [9.60173428e-01],\n",
       "       [9.99762952e-01],\n",
       "       [9.93465602e-01],\n",
       "       [9.93095040e-01],\n",
       "       [3.68915760e-04],\n",
       "       [7.40307150e-05],\n",
       "       [7.97036171e-01],\n",
       "       [1.40815223e-06],\n",
       "       [9.83904779e-01],\n",
       "       [9.99783576e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99988794e-01],\n",
       "       [9.99880314e-01],\n",
       "       [9.99999642e-01],\n",
       "       [9.99990106e-01],\n",
       "       [9.88537550e-01],\n",
       "       [9.68260586e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.65813673e-01],\n",
       "       [1.72700852e-01],\n",
       "       [4.47685261e-06],\n",
       "       [9.99954104e-01],\n",
       "       [9.91980076e-01],\n",
       "       [4.00769088e-04],\n",
       "       [9.97383893e-01],\n",
       "       [9.99855638e-01],\n",
       "       [9.99970913e-01],\n",
       "       [9.99999762e-01],\n",
       "       [5.89829087e-01],\n",
       "       [6.03055768e-02],\n",
       "       [2.23818221e-04],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999762e-01],\n",
       "       [2.46437127e-03],\n",
       "       [9.10727918e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.98194396e-01],\n",
       "       [9.38269113e-06],\n",
       "       [6.80260855e-05],\n",
       "       [9.99735057e-01],\n",
       "       [1.42990148e-05],\n",
       "       [1.00000000e+00],\n",
       "       [9.99997020e-01],\n",
       "       [9.97343838e-01],\n",
       "       [9.77385998e-01],\n",
       "       [4.18543845e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99677062e-01],\n",
       "       [9.82838154e-01],\n",
       "       [9.92473483e-01],\n",
       "       [9.99963403e-01],\n",
       "       [9.99999046e-01],\n",
       "       [1.61570997e-03],\n",
       "       [1.00000000e+00],\n",
       "       [9.69880641e-01],\n",
       "       [9.99998808e-01],\n",
       "       [3.70813698e-01],\n",
       "       [5.01991326e-06],\n",
       "       [9.99710679e-01],\n",
       "       [9.99012768e-01],\n",
       "       [6.10096959e-06],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999881e-01],\n",
       "       [9.91889417e-01],\n",
       "       [5.37488304e-05],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999642e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.42431764e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.08450001e-06],\n",
       "       [4.86655117e-05],\n",
       "       [9.99999762e-01],\n",
       "       [9.99990106e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99902844e-01],\n",
       "       [5.33955634e-01],\n",
       "       [9.99999881e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99965787e-01],\n",
       "       [8.11939597e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.83645797e-01],\n",
       "       [5.94137788e-01],\n",
       "       [5.52665949e-01],\n",
       "       [1.89827242e-05],\n",
       "       [6.77465287e-05],\n",
       "       [9.42282736e-01],\n",
       "       [9.99986053e-01],\n",
       "       [9.97927308e-01],\n",
       "       [7.37894470e-06],\n",
       "       [1.43009871e-01],\n",
       "       [9.98138428e-01],\n",
       "       [9.99790490e-01],\n",
       "       [9.95531261e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99991298e-01],\n",
       "       [8.27261556e-06],\n",
       "       [9.97755269e-05],\n",
       "       [9.99983788e-01],\n",
       "       [9.99999642e-01],\n",
       "       [1.12313144e-04],\n",
       "       [1.00000000e+00],\n",
       "       [3.37426364e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.99999404e-01],\n",
       "       [2.38714084e-01],\n",
       "       [4.20025899e-04],\n",
       "       [1.00000000e+00],\n",
       "       [2.60556408e-04],\n",
       "       [2.46746367e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.66187298e-01],\n",
       "       [9.99973178e-01],\n",
       "       [5.90511978e-01],\n",
       "       [1.04924003e-02],\n",
       "       [3.97986213e-08],\n",
       "       [9.96883512e-01],\n",
       "       [9.98713493e-01],\n",
       "       [9.99958634e-01],\n",
       "       [9.93411362e-01],\n",
       "       [3.86673690e-07],\n",
       "       [9.99977589e-01],\n",
       "       [8.82666767e-01],\n",
       "       [9.99991179e-01],\n",
       "       [8.37877451e-04],\n",
       "       [9.57303226e-01],\n",
       "       [9.99981403e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999762e-01],\n",
       "       [6.65418020e-06],\n",
       "       [9.96969044e-01],\n",
       "       [9.98421431e-01],\n",
       "       [9.52157021e-01],\n",
       "       [5.49175581e-07],\n",
       "       [9.99998689e-01],\n",
       "       [4.97840752e-04],\n",
       "       [9.99164701e-01],\n",
       "       [9.99994516e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.26051768e-07],\n",
       "       [1.29260274e-03],\n",
       "       [1.00000000e+00],\n",
       "       [9.99653935e-01],\n",
       "       [3.50380272e-01],\n",
       "       [2.75139451e-01],\n",
       "       [1.69890249e-04],\n",
       "       [6.76169038e-01],\n",
       "       [9.72205639e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99997973e-01],\n",
       "       [9.85469341e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99972939e-01],\n",
       "       [9.83181298e-01],\n",
       "       [3.55668817e-05],\n",
       "       [3.16337446e-06],\n",
       "       [9.99796093e-01],\n",
       "       [9.93710876e-01],\n",
       "       [1.63766856e-07],\n",
       "       [7.81041963e-05],\n",
       "       [2.05967858e-01],\n",
       "       [9.54337239e-01],\n",
       "       [9.75039293e-05],\n",
       "       [9.97458398e-01],\n",
       "       [4.67020470e-07],\n",
       "       [6.29857368e-07],\n",
       "       [1.00000000e+00],\n",
       "       [5.61716831e-07],\n",
       "       [9.89509702e-01],\n",
       "       [9.99994755e-01],\n",
       "       [9.99774873e-01],\n",
       "       [9.92256045e-01],\n",
       "       [8.74986708e-01],\n",
       "       [9.99964714e-01],\n",
       "       [9.99997497e-01],\n",
       "       [3.66804716e-06],\n",
       "       [2.87175030e-01],\n",
       "       [2.28571962e-03],\n",
       "       [9.92370844e-01],\n",
       "       [1.07857375e-03],\n",
       "       [9.99971151e-01],\n",
       "       [9.99997497e-01],\n",
       "       [9.99979973e-01],\n",
       "       [9.99946117e-01],\n",
       "       [1.67362858e-03],\n",
       "       [3.73234025e-06],\n",
       "       [9.99991894e-01],\n",
       "       [9.94691133e-01],\n",
       "       [9.99899745e-01],\n",
       "       [9.99971032e-01],\n",
       "       [1.93123469e-06],\n",
       "       [9.99987960e-01],\n",
       "       [9.99999642e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [6.22123361e-01],\n",
       "       [9.93788362e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [5.52059792e-05],\n",
       "       [9.99123752e-01],\n",
       "       [9.99911189e-01],\n",
       "       [9.99999881e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.96572256e-01],\n",
       "       [9.99996781e-01],\n",
       "       [9.99999762e-01],\n",
       "       [6.54668042e-07],\n",
       "       [9.99469340e-01],\n",
       "       [9.99950886e-01],\n",
       "       [9.99899626e-01],\n",
       "       [9.99999046e-01],\n",
       "       [9.95648205e-01],\n",
       "       [1.00000000e+00],\n",
       "       [7.92663813e-01],\n",
       "       [9.95718896e-01],\n",
       "       [1.19215611e-06],\n",
       "       [3.07896864e-02],\n",
       "       [9.97354627e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [6.96135402e-01],\n",
       "       [9.87054944e-01],\n",
       "       [9.58400249e-01],\n",
       "       [9.99993086e-01],\n",
       "       [8.80257845e-01],\n",
       "       [9.96639609e-01],\n",
       "       [9.99893188e-01],\n",
       "       [9.99994516e-01],\n",
       "       [1.41293883e-01],\n",
       "       [9.99996543e-01],\n",
       "       [4.69038923e-07],\n",
       "       [9.99976397e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99748766e-01],\n",
       "       [9.99807060e-01],\n",
       "       [1.00000000e+00],\n",
       "       [6.67833738e-05],\n",
       "       [4.68603639e-06],\n",
       "       [9.42210609e-05],\n",
       "       [9.15421963e-01],\n",
       "       [2.17815739e-07],\n",
       "       [1.00000000e+00],\n",
       "       [9.98152733e-01],\n",
       "       [9.99805748e-01],\n",
       "       [1.48250267e-01],\n",
       "       [9.99104738e-01],\n",
       "       [2.52170963e-07],\n",
       "       [9.99998569e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.98143077e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.93163943e-01],\n",
       "       [8.83425534e-01],\n",
       "       [9.99942660e-01],\n",
       "       [1.63736672e-03],\n",
       "       [8.24313641e-01],\n",
       "       [9.99961019e-01],\n",
       "       [9.91074502e-01],\n",
       "       [3.08090908e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.74624529e-06],\n",
       "       [2.33550541e-04],\n",
       "       [9.99995112e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.95507717e-01],\n",
       "       [1.00000000e+00],\n",
       "       [7.14873374e-02],\n",
       "       [9.98538375e-01],\n",
       "       [9.78665888e-01],\n",
       "       [6.77345611e-08],\n",
       "       [1.00000000e+00],\n",
       "       [9.87492800e-01],\n",
       "       [9.99983668e-01],\n",
       "       [9.98659253e-01],\n",
       "       [9.75521624e-01],\n",
       "       [9.94399369e-01],\n",
       "       [6.44385068e-07],\n",
       "       [9.79777157e-01],\n",
       "       [4.47233677e-01],\n",
       "       [9.97790694e-01],\n",
       "       [6.39506766e-07],\n",
       "       [9.99999881e-01],\n",
       "       [3.35911545e-03],\n",
       "       [9.99487817e-01],\n",
       "       [9.97788429e-01],\n",
       "       [9.69712198e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99984980e-01],\n",
       "       [9.99900341e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.86026025e-01],\n",
       "       [9.99997258e-01],\n",
       "       [7.95107409e-02],\n",
       "       [9.99982595e-01],\n",
       "       [4.09485012e-01],\n",
       "       [9.99672890e-01],\n",
       "       [9.99941468e-01],\n",
       "       [2.11400970e-06],\n",
       "       [9.91800606e-01],\n",
       "       [9.99992847e-01],\n",
       "       [9.99961138e-01],\n",
       "       [1.23452469e-06],\n",
       "       [1.84846215e-06],\n",
       "       [9.99999762e-01],\n",
       "       [9.99895692e-01],\n",
       "       [1.37136499e-06],\n",
       "       [1.00000000e+00],\n",
       "       [1.26919549e-04],\n",
       "       [9.99047220e-01],\n",
       "       [1.82406162e-04],\n",
       "       [1.00000000e+00],\n",
       "       [9.99909401e-01],\n",
       "       [4.02219768e-04],\n",
       "       [1.00000000e+00],\n",
       "       [9.99991655e-01],\n",
       "       [9.99994993e-01],\n",
       "       [1.97685083e-07],\n",
       "       [1.28481224e-06],\n",
       "       [4.58279857e-04],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999881e-01],\n",
       "       [4.17776763e-01],\n",
       "       [1.34348273e-02],\n",
       "       [1.00000000e+00],\n",
       "       [8.31712210e-09],\n",
       "       [5.20188541e-06],\n",
       "       [9.99013007e-01],\n",
       "       [9.99965072e-01],\n",
       "       [9.00695562e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.47290732e-04],\n",
       "       [9.99997497e-01],\n",
       "       [9.99999523e-01],\n",
       "       [8.49919200e-01],\n",
       "       [9.87011969e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.95747626e-01],\n",
       "       [9.99990821e-01],\n",
       "       [9.99670625e-01],\n",
       "       [9.99812186e-01],\n",
       "       [1.03730088e-06],\n",
       "       [1.22276765e-06],\n",
       "       [2.01584096e-03],\n",
       "       [1.82044096e-06],\n",
       "       [1.00000000e+00],\n",
       "       [9.98983264e-01],\n",
       "       [5.87026761e-06],\n",
       "       [5.56657938e-07],\n",
       "       [1.00000000e+00],\n",
       "       [9.97982681e-01],\n",
       "       [9.99564350e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.40996170e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.84298587e-01],\n",
       "       [5.95887650e-06],\n",
       "       [9.99949336e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.23321659e-06],\n",
       "       [9.99993682e-01],\n",
       "       [9.99999404e-01],\n",
       "       [7.34810114e-01],\n",
       "       [6.62957435e-04],\n",
       "       [1.00000000e+00],\n",
       "       [5.02981175e-06],\n",
       "       [2.47247663e-05],\n",
       "       [3.76763684e-03],\n",
       "       [9.97280180e-01],\n",
       "       [9.99999881e-01],\n",
       "       [1.06111613e-04],\n",
       "       [9.98709083e-01],\n",
       "       [9.99999762e-01],\n",
       "       [9.99999642e-01],\n",
       "       [8.00352216e-01],\n",
       "       [1.99782383e-03],\n",
       "       [9.74614231e-04],\n",
       "       [9.99997139e-01],\n",
       "       [9.99988437e-01],\n",
       "       [2.30994738e-06],\n",
       "       [9.97008026e-01],\n",
       "       [9.93310452e-01],\n",
       "       [1.08056804e-02],\n",
       "       [9.99999523e-01],\n",
       "       [9.92902100e-01],\n",
       "       [9.91781890e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.97961879e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99998808e-01],\n",
       "       [9.99660015e-01],\n",
       "       [9.12056625e-01],\n",
       "       [9.99999762e-01],\n",
       "       [9.46315169e-01],\n",
       "       [9.99952555e-01],\n",
       "       [4.01163280e-01],\n",
       "       [9.99921918e-01],\n",
       "       [9.95995164e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.97765541e-01],\n",
       "       [9.99975324e-01],\n",
       "       [1.16136925e-06],\n",
       "       [9.99999762e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99996424e-01],\n",
       "       [9.92348552e-01],\n",
       "       [1.69548453e-04],\n",
       "       [9.84874070e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99981761e-01],\n",
       "       [7.47245014e-01],\n",
       "       [2.07058542e-06],\n",
       "       [9.17368293e-01],\n",
       "       [9.58780587e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.31203137e-06],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999762e-01],\n",
       "       [6.57166936e-04],\n",
       "       [9.88750756e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.62903905e-05],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999762e-01],\n",
       "       [9.94290948e-01],\n",
       "       [9.99984980e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999404e-01],\n",
       "       [2.95882820e-08],\n",
       "       [9.99999881e-01],\n",
       "       [9.99986529e-01],\n",
       "       [9.98752117e-01],\n",
       "       [9.22465205e-01],\n",
       "       [8.61173749e-01],\n",
       "       [1.36146350e-02],\n",
       "       [9.81038928e-01],\n",
       "       [1.38075688e-04],\n",
       "       [9.99999881e-01],\n",
       "       [1.72967866e-01],\n",
       "       [9.99999523e-01],\n",
       "       [1.50258870e-06],\n",
       "       [3.54483632e-06],\n",
       "       [9.99631524e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.05391121e-01],\n",
       "       [9.99980927e-01],\n",
       "       [9.99925017e-01],\n",
       "       [8.81393969e-01],\n",
       "       [5.63044623e-02],\n",
       "       [9.99999881e-01],\n",
       "       [8.84808779e-01],\n",
       "       [9.99778569e-01],\n",
       "       [9.99862313e-01],\n",
       "       [7.01287761e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [1.81812482e-06],\n",
       "       [9.99999762e-01],\n",
       "       [9.41885592e-05],\n",
       "       [1.96230989e-02],\n",
       "       [9.99998927e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99998808e-01],\n",
       "       [9.35044765e-01],\n",
       "       [6.93436623e-01],\n",
       "       [9.95674372e-01],\n",
       "       [8.91574193e-04],\n",
       "       [2.72148696e-07],\n",
       "       [9.99980211e-01],\n",
       "       [9.36911941e-01],\n",
       "       [9.97675478e-01],\n",
       "       [9.13921654e-01],\n",
       "       [9.99978304e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.99999881e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.10469628e-05],\n",
       "       [1.52263829e-06],\n",
       "       [9.99938607e-01],\n",
       "       [9.99999642e-01],\n",
       "       [9.99911785e-01],\n",
       "       [9.99999642e-01],\n",
       "       [2.16784457e-09],\n",
       "       [7.63414937e-05],\n",
       "       [2.93376215e-04],\n",
       "       [8.87141645e-01],\n",
       "       [9.80067134e-01],\n",
       "       [9.94509995e-01],\n",
       "       [9.99983430e-01],\n",
       "       [9.51813757e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.48466003e-01],\n",
       "       [9.15979967e-03],\n",
       "       [9.99980330e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.63762522e-01],\n",
       "       [7.38147181e-04],\n",
       "       [1.81742089e-05],\n",
       "       [1.00000000e+00],\n",
       "       [5.81864357e-01],\n",
       "       [9.41604257e-01],\n",
       "       [9.89823369e-04],\n",
       "       [1.78727176e-04],\n",
       "       [9.99999166e-01],\n",
       "       [5.40630937e-01],\n",
       "       [9.96985018e-01],\n",
       "       [9.99976158e-01],\n",
       "       [9.99976397e-01],\n",
       "       [5.90036154e-01],\n",
       "       [9.99969959e-01],\n",
       "       [9.50327456e-01],\n",
       "       [4.34681326e-01],\n",
       "       [3.19487840e-01],\n",
       "       [1.42116754e-04],\n",
       "       [6.23400807e-01]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(models[0].predict(test_images))\n",
    "#(ensemble_model.predict(test_images) >= 0.5).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0827767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://24ffe016-3bcc-436a-be61-e2b530a64526/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://24ffe016-3bcc-436a-be61-e2b530a64526/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save all the trained models in a list\n",
    "with open('kfold_models.pkl', 'wb') as f:\n",
    "  pickle.dump(models, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "150f938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load all the trained models from the list\n",
    "with open('kfold_models.pkl', 'rb') as g:\n",
    "  models2 = pickle.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f89e5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.functional.Functional at 0x28fcac9a0>,\n",
       " <keras.engine.functional.Functional at 0x28fcac9a0>,\n",
       " <keras.engine.functional.Functional at 0x28fcac9a0>,\n",
       " <keras.engine.functional.Functional at 0x28fcac9a0>,\n",
       " <keras.engine.functional.Functional at 0x28fcac9a0>,\n",
       " <keras.engine.functional.Functional at 0x28fcac9a0>,\n",
       " <keras.engine.functional.Functional at 0x28fcac9a0>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9ee8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 1s 31ms/step\n",
      "17/17 [==============================] - 0s 23ms/step\n",
      "17/17 [==============================] - 0s 23ms/step\n",
      "17/17 [==============================] - 0s 23ms/step\n",
      "17/17 [==============================] - 0s 23ms/step\n",
      "17/17 [==============================] - 0s 23ms/step\n",
      "17/17 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make predictions with each trained model\n",
    "predictions = [model.predict(test_images) for model in models2]\n",
    "\n",
    "\n",
    "#(models[0].predict(test_images))\n",
    "\n",
    "# Weighted average of the predictions\n",
    "prediction = np.average(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e1ad5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction>=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b091d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
